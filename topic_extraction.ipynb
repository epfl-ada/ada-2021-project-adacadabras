{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ada/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import spacy, nltk, gensim, sklearn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quoteID</th>\n",
       "      <th>quotation</th>\n",
       "      <th>speaker</th>\n",
       "      <th>qids</th>\n",
       "      <th>date</th>\n",
       "      <th>numOccurrences</th>\n",
       "      <th>probas</th>\n",
       "      <th>urls</th>\n",
       "      <th>phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-05-16-000278</td>\n",
       "      <td>[ Malia ] knows what she is going to do. They ...</td>\n",
       "      <td>Paul Bryant</td>\n",
       "      <td>[Q2059029]</td>\n",
       "      <td>2016-05-16 11:44:37</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Paul Bryant, 0.9197], [None, 0.0803]]</td>\n",
       "      <td>[http://walb.com/story/31980641/some-colleges-...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-12-12-000423</td>\n",
       "      <td>[ t ] o fail to acknowledge even our most basi...</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>2016-12-12 16:59:39</td>\n",
       "      <td>1</td>\n",
       "      <td>[[None, 0.7828], [Tuan Anh, 0.2172]]</td>\n",
       "      <td>[http://cnsnews.com/commentary/lynn-wardle/ark...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-09-23-000654</td>\n",
       "      <td>... the abortion pill really shows how unworka...</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>2016-09-23 13:53:34</td>\n",
       "      <td>1</td>\n",
       "      <td>[[None, 0.9435], [Ruth Coppinger, 0.0565]]</td>\n",
       "      <td>[http://www.universityobserver.ie/news/ruth-co...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-04-29-000706</td>\n",
       "      <td>[ W ] omen who carry unwanted pregnancies to t...</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>2016-04-29 23:17:07</td>\n",
       "      <td>1</td>\n",
       "      <td>[[None, 0.8603], [Sheila Solon, 0.1397]]</td>\n",
       "      <td>[http://grist.org/living/slide-into-my-dms-and...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01-000274</td>\n",
       "      <td>(1) the allegations underlying this matter, wh...</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>2016-01-01 02:44:51</td>\n",
       "      <td>1</td>\n",
       "      <td>[[None, 0.7972], [Camille Cosby, 0.2028]]</td>\n",
       "      <td>[http://www.bostonglobe.com/metro/2015/12/31/w...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>2016-08-22-075227</td>\n",
       "      <td>She walks and breathes and you can't stop star...</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>2016-08-22 07:44:52</td>\n",
       "      <td>1</td>\n",
       "      <td>[[None, 0.7862], [Judi Dench, 0.1372], [George...</td>\n",
       "      <td>[http://tallahassee.com/story/entertainment/20...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>2016-05-09-072733</td>\n",
       "      <td>She wanted to have a glow for the red carpet,</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>2016-05-09 14:54:26</td>\n",
       "      <td>3</td>\n",
       "      <td>[[None, 0.7656], [Kim Kardashian, 0.2344]]</td>\n",
       "      <td>[http://dailycaller.com/2016/05/09/kim-kardash...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>2016-09-15-096186</td>\n",
       "      <td>She wants to hurt me,</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>2016-09-15 07:25:29</td>\n",
       "      <td>1</td>\n",
       "      <td>[[None, 0.9091], [Peter Weber, 0.0909]]</td>\n",
       "      <td>[http://theweek.com/speedreads/648952/heres-st...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>2016-05-07-042258</td>\n",
       "      <td>SHE WAS A GIFTED INSTRUCTOR WHO TAUGHT SCIENCE...</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>2016-05-07 10:45:30</td>\n",
       "      <td>6</td>\n",
       "      <td>[[None, 0.681], [Tim Cruz, 0.1453], [John Hann...</td>\n",
       "      <td>[http://wcvb.com/news/quincy-college-professor...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>2016-09-16-090139</td>\n",
       "      <td>She was a very bright, capable woman, and it w...</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>2016-09-16 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>[[None, 0.9193], [Ginger Strand, 0.0807]]</td>\n",
       "      <td>[http://www.dailygazette.com/news/2016/sep/16/...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                quoteID                                          quotation  \\\n",
       "0     2016-05-16-000278  [ Malia ] knows what she is going to do. They ...   \n",
       "1     2016-12-12-000423  [ t ] o fail to acknowledge even our most basi...   \n",
       "2     2016-09-23-000654  ... the abortion pill really shows how unworka...   \n",
       "3     2016-04-29-000706  [ W ] omen who carry unwanted pregnancies to t...   \n",
       "4     2016-01-01-000274  (1) the allegations underlying this matter, wh...   \n",
       "...                 ...                                                ...   \n",
       "4995  2016-08-22-075227  She walks and breathes and you can't stop star...   \n",
       "4996  2016-05-09-072733      She wanted to have a glow for the red carpet,   \n",
       "4997  2016-09-15-096186                              She wants to hurt me,   \n",
       "4998  2016-05-07-042258  SHE WAS A GIFTED INSTRUCTOR WHO TAUGHT SCIENCE...   \n",
       "4999  2016-09-16-090139  She was a very bright, capable woman, and it w...   \n",
       "\n",
       "          speaker        qids                date  numOccurrences  \\\n",
       "0     Paul Bryant  [Q2059029] 2016-05-16 11:44:37               1   \n",
       "1            None          [] 2016-12-12 16:59:39               1   \n",
       "2            None          [] 2016-09-23 13:53:34               1   \n",
       "3            None          [] 2016-04-29 23:17:07               1   \n",
       "4            None          [] 2016-01-01 02:44:51               1   \n",
       "...           ...         ...                 ...             ...   \n",
       "4995         None          [] 2016-08-22 07:44:52               1   \n",
       "4996         None          [] 2016-05-09 14:54:26               3   \n",
       "4997         None          [] 2016-09-15 07:25:29               1   \n",
       "4998         None          [] 2016-05-07 10:45:30               6   \n",
       "4999         None          [] 2016-09-16 00:00:00               1   \n",
       "\n",
       "                                                 probas  \\\n",
       "0               [[Paul Bryant, 0.9197], [None, 0.0803]]   \n",
       "1                  [[None, 0.7828], [Tuan Anh, 0.2172]]   \n",
       "2            [[None, 0.9435], [Ruth Coppinger, 0.0565]]   \n",
       "3              [[None, 0.8603], [Sheila Solon, 0.1397]]   \n",
       "4             [[None, 0.7972], [Camille Cosby, 0.2028]]   \n",
       "...                                                 ...   \n",
       "4995  [[None, 0.7862], [Judi Dench, 0.1372], [George...   \n",
       "4996         [[None, 0.7656], [Kim Kardashian, 0.2344]]   \n",
       "4997            [[None, 0.9091], [Peter Weber, 0.0909]]   \n",
       "4998  [[None, 0.681], [Tim Cruz, 0.1453], [John Hann...   \n",
       "4999          [[None, 0.9193], [Ginger Strand, 0.0807]]   \n",
       "\n",
       "                                                   urls phase  \n",
       "0     [http://walb.com/story/31980641/some-colleges-...     E  \n",
       "1     [http://cnsnews.com/commentary/lynn-wardle/ark...     E  \n",
       "2     [http://www.universityobserver.ie/news/ruth-co...     E  \n",
       "3     [http://grist.org/living/slide-into-my-dms-and...     E  \n",
       "4     [http://www.bostonglobe.com/metro/2015/12/31/w...     E  \n",
       "...                                                 ...   ...  \n",
       "4995  [http://tallahassee.com/story/entertainment/20...     E  \n",
       "4996  [http://dailycaller.com/2016/05/09/kim-kardash...     E  \n",
       "4997  [http://theweek.com/speedreads/648952/heres-st...     E  \n",
       "4998  [http://wcvb.com/news/quincy-college-professor...     E  \n",
       "4999  [http://www.dailygazette.com/news/2016/sep/16/...     E  \n",
       "\n",
       "[5000 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = 2016 # available: from 2015 to 2020\n",
    "PATH_DATA = './data/data_nlp/'\n",
    "QUOTES_FILE = PATH_DATA + f'quotes-{year}-filtered.json.bz2'\n",
    "CHUNK_SIZE = 5000\n",
    "\n",
    "reader = pd.read_json(QUOTES_FILE, lines=True, compression='bz2', chunksize=CHUNK_SIZE, typ='frame')\n",
    "\n",
    "for chunk in reader:\n",
    "    df_0 = chunk\n",
    "    break\n",
    "df_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[ Malia ] knows what she is going to do. They have a plan for her and her family feels comfortable knowing that it's not something unstructured, [ t ] o fail to acknowledge even our most basic biological differences -- such as the fact that a mother must be present at birth but the father need not be -- risks making the guarantee of equal protection superficial, and so disserving it. Mechanistic classification of all our differences as stereotypes would operate to obscure those misconceptions and prejudices that are real. The distinction embodied in the statutory scheme here at issue is not ma\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Putting all the quotes in one corpus\n",
    "text = \"\"\n",
    "\n",
    "for quote in df_0.quotation:\n",
    "    text = text + ' ' + quote\n",
    "\n",
    "#Removing the new lines\n",
    "text = \" \".join(text.split())\n",
    "text[:600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a's</td>\n",
       "      <td>able</td>\n",
       "      <td>about</td>\n",
       "      <td>above</td>\n",
       "      <td>according</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accordingly</td>\n",
       "      <td>across</td>\n",
       "      <td>actually</td>\n",
       "      <td>after</td>\n",
       "      <td>afterwards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>again</td>\n",
       "      <td>against</td>\n",
       "      <td>ain't</td>\n",
       "      <td>all</td>\n",
       "      <td>allow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allows</td>\n",
       "      <td>almost</td>\n",
       "      <td>alone</td>\n",
       "      <td>along</td>\n",
       "      <td>already</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>also</td>\n",
       "      <td>although</td>\n",
       "      <td>always</td>\n",
       "      <td>am</td>\n",
       "      <td>among</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>why</td>\n",
       "      <td>will</td>\n",
       "      <td>willing</td>\n",
       "      <td>wish</td>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>within</td>\n",
       "      <td>without</td>\n",
       "      <td>won't</td>\n",
       "      <td>wonder</td>\n",
       "      <td>would</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>wouldn't</td>\n",
       "      <td>yes</td>\n",
       "      <td>yet</td>\n",
       "      <td>you</td>\n",
       "      <td>you'd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>you'll</td>\n",
       "      <td>you're</td>\n",
       "      <td>you've</td>\n",
       "      <td>your</td>\n",
       "      <td>yours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>yourself</td>\n",
       "      <td>yourselves</td>\n",
       "      <td>zero</td>\n",
       "      <td>`</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1         2       3           4\n",
       "0            a's        able     about   above   according\n",
       "1    accordingly      across  actually   after  afterwards\n",
       "2          again     against     ain't     all       allow\n",
       "3         allows      almost     alone   along     already\n",
       "4           also    although    always      am       among\n",
       "..           ...         ...       ...     ...         ...\n",
       "104          why        will   willing    wish        with\n",
       "105       within     without     won't  wonder       would\n",
       "106     wouldn't         yes       yet     you       you'd\n",
       "107       you'll      you're    you've    your       yours\n",
       "108     yourself  yourselves      zero       `         NaN\n",
       "\n",
       "[109 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = PATH_DATA + 'stopword_list.csv'\n",
    "sw = pd.read_csv(PATH, header=None)\n",
    "sw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "871\n"
     ]
    }
   ],
   "source": [
    "#loading default spacy stopword list\n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "len(spacy_stopwords)\n",
    "\n",
    "#creating new stopword list\n",
    "sw_list = list(sw[0]) + list(sw[1]) + list(sw[2]) + list(sw[3]) + list(sw[4]) + list(spacy_stopwords)\n",
    "nlp.Defaults.stop_words = sw_list\n",
    "\n",
    "print(len(nlp.Defaults.stop_words))\n",
    "\n",
    "#crearing a spacy object\n",
    "doc = nlp(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176970"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [token.text for token in doc]\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100473"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of stopwords detected in text\n",
    "stop_words = [token.text for token in doc if token.is_stop]\n",
    "len(stop_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57070"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [token.text for token in doc if token.is_stop != True and token.is_punct != True]\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('women', 604), ('people', 367), ('time', 335), ('woman', 269), ('years', 207), ('life', 200), ('year', 194), ('good', 193), ('lot', 190), ('girls', 189), ('family', 183), ('mother', 183), ('work', 180), ('great', 178), ('girl', 168), ('love', 162), ('day', 159), ('wife', 152), ('men', 149), ('things', 129), ('thing', 129), ('told', 128), ('dollars', 127), ('Clinton', 124), ('world', 122), ('children', 119), ('home', 118), ('person', 118), ('wanted', 114), ('daughter', 109), ('man', 109), ('country', 108), ('young', 106), ('kind', 103), ('Hillary', 103), ('sexual', 99), ('hard', 98), ('feel', 94), ('child', 91), ('support', 91), ('sex', 90), ('female', 88), ('team', 87), ('long', 86), ('working', 85), ('Trump', 83), ('big', 81), ('knew', 81), ('mom', 79), ('sister', 77), ('marriage', 75), ('play', 75), ('school', 73), ('important', 73), ('thought', 73), ('married', 73), ('kids', 73), ('money', 73), ('started', 70), ('happy', 70), ('real', 69), ('job', 69), ('times', 68), ('felt', 68), ('care', 68), ('public', 67), ('state', 67), ('story', 67), ('friends', 67), ('dollar', 66), ('friend', 66), ('place', 66), ('making', 65), ('proud', 63), ('film', 62), ('end', 60), ('house', 60), ('gave', 59), ('Women', 59), ('talk', 59), ('fact', 58), ('experience', 58), ('Virginia', 58), ('change', 57), ('loved', 57), ('law', 56), ('community', 56), ('asked', 56), ('father', 55), ('strong', 55), ('excited', 55), ('$', 54), ('today', 54), ('husband', 54), ('relationship', 54), ('lady', 54), ('bit', 54), ('high', 53), ('game', 52), ('students', 52)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# five most common tokens\n",
    "word_freq = Counter(words)\n",
    "word_freq.most_common()\n",
    "print(word_freq.most_common(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ddbd0b842a978e03471eb3a4ae18fdd24eb8ad76bdab23b363108c4c8f6a59c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('ada': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
