{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADAcadabras Milestone 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Notebook containing main methods used to deal with the raw data, process it, and extract the main figures which will let us conduct our analysis.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you will see, this notebook only loads and analyses the data from year 2020, considering it as the smallest dataset. Running the notebook as a TA for all years would constitute a large chunk of time, which is why the notebook will only address 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Libraries used:***\n",
    "- python=3.8.12\n",
    "- pandas\n",
    "- datetime\n",
    "- time\n",
    "- matplotlib\n",
    "- seaborn\n",
    "- scipy\n",
    "- pickle\n",
    "- bz2\n",
    "- json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Files and directories to make this notebook run successfully:***\n",
    "\n",
    "- **data/**\n",
    "  - **parquet/**\n",
    "    - *speaker_attributes.parquet*\n",
    "    - *wikidata_labels_descriptions_quotebank.csv.bz2*\n",
    "  - **filtered/**\n",
    "    - **pickles/**\n",
    "      - *quotes-2020-filtered.pkl.bz2*\n",
    "    - *quotes-2020-filtered.json.bz2*\n",
    "  - *quotes-2020.json.bz2*\n",
    "- *data_processing.ipynb*\n",
    "- *helper.py*\n",
    "\n",
    "\n",
    "\n",
    "Directories are in **bold** and files are in *italic*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Creating dataset D1 and analysing it(see README)***\n",
    "\n",
    "We will extract the numbers we need from it all at once so we won't need to store it in memory since it represents the full Quotebank dataset from 2015 to 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = 'data/'\n",
    "PATH_PARQUET = PATH_DATA + 'parquet/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an array containing all years of our study `[2015;2020]` and then create a loop on all the years. This notebook will only deal with the data from 2020 so that the TA's can run it in a reasonable amount of time during correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/quotes-2020.json.bz2'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The full version had range(2015, 2021) instead to include all years\n",
    "# In later cells, a for loop would be necessary to read from all files\n",
    "years = range(2020, 2021)\n",
    "QUOTES_FILE = [PATH_DATA + f'quotes-{year}.json.bz2' for year in years]\n",
    "\n",
    "if len(QUOTES_FILE) == 1:\n",
    "    QUOTES_FILE = QUOTES_FILE[0]\n",
    "QUOTES_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARQUET_FILE = PATH_PARQUET + 'speaker_attributes.parquet'\n",
    "WIKIDATA_LABELS_FILE = PATH_PARQUET + 'wikidata_labels_descriptions_quotebank.csv.bz2'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Load Quotebank data into many chunks***\n",
    "\n",
    "Loading into chunks makes the machine handle the large database in order to fit it into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 1e5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.01 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reader_2020 = pd.read_json(QUOTES_FILE, lines=True, compression='bz2', chunksize=CHUNK_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quoteID</th>\n",
       "      <th>quotation</th>\n",
       "      <th>speaker</th>\n",
       "      <th>qids</th>\n",
       "      <th>date</th>\n",
       "      <th>numOccurrences</th>\n",
       "      <th>probas</th>\n",
       "      <th>urls</th>\n",
       "      <th>phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24553</th>\n",
       "      <td>2020-02-11-081493</td>\n",
       "      <td>the funniest comic book film since `Deadpool' ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>2020-02-11 16:03:06</td>\n",
       "      <td>1</td>\n",
       "      <td>[[None, 0.8202], [Margot Robbie, 0.06], [Jared...</td>\n",
       "      <td>[https://nypost.com/2020/02/11/birds-of-prey-g...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30517</th>\n",
       "      <td>2020-01-15-003307</td>\n",
       "      <td>After years of austerity under the Tories, the...</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>2020-01-15 12:35:55</td>\n",
       "      <td>9</td>\n",
       "      <td>[[None, 0.8452], [Matt Hancock, 0.1548]]</td>\n",
       "      <td>[https://www.politicshome.com/news/uk/health-a...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17456</th>\n",
       "      <td>2020-02-02-054290</td>\n",
       "      <td>Well done everybody, you have all worked very ...</td>\n",
       "      <td>Jim Davidson</td>\n",
       "      <td>[Q1460459, Q2559713, Q6194541]</td>\n",
       "      <td>2020-02-02 00:01:00</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Jim Davidson, 0.7671], [None, 0.1339], [Nige...</td>\n",
       "      <td>[http://express.co.uk/news/politics/1236727/br...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98698</th>\n",
       "      <td>2020-02-26-039773</td>\n",
       "      <td>It was a case of them pitching me the title; n...</td>\n",
       "      <td>Leigh Whannell</td>\n",
       "      <td>[Q471215]</td>\n",
       "      <td>2020-02-26 12:00:00</td>\n",
       "      <td>13</td>\n",
       "      <td>[[Leigh Whannell, 0.6972], [None, 0.2426], [To...</td>\n",
       "      <td>[http://www.noosanews.com.au/news/what-you-don...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64621</th>\n",
       "      <td>2020-01-30-031100</td>\n",
       "      <td>I couldn't be more excited to step up the show...</td>\n",
       "      <td>Dom Dolla</td>\n",
       "      <td>[Q58007869]</td>\n",
       "      <td>2020-01-30 09:02:04</td>\n",
       "      <td>2</td>\n",
       "      <td>[[Dom Dolla, 0.5869], [None, 0.4131]]</td>\n",
       "      <td>[https://musicfeeds.com.au/news/dom-dolla-has-...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 quoteID                                          quotation  \\\n",
       "24553  2020-02-11-081493  the funniest comic book film since `Deadpool' ...   \n",
       "30517  2020-01-15-003307  After years of austerity under the Tories, the...   \n",
       "17456  2020-02-02-054290  Well done everybody, you have all worked very ...   \n",
       "98698  2020-02-26-039773  It was a case of them pitching me the title; n...   \n",
       "64621  2020-01-30-031100  I couldn't be more excited to step up the show...   \n",
       "\n",
       "              speaker                            qids                date  \\\n",
       "24553            None                              [] 2020-02-11 16:03:06   \n",
       "30517            None                              [] 2020-01-15 12:35:55   \n",
       "17456    Jim Davidson  [Q1460459, Q2559713, Q6194541] 2020-02-02 00:01:00   \n",
       "98698  Leigh Whannell                       [Q471215] 2020-02-26 12:00:00   \n",
       "64621       Dom Dolla                     [Q58007869] 2020-01-30 09:02:04   \n",
       "\n",
       "       numOccurrences                                             probas  \\\n",
       "24553               1  [[None, 0.8202], [Margot Robbie, 0.06], [Jared...   \n",
       "30517               9           [[None, 0.8452], [Matt Hancock, 0.1548]]   \n",
       "17456               1  [[Jim Davidson, 0.7671], [None, 0.1339], [Nige...   \n",
       "98698              13  [[Leigh Whannell, 0.6972], [None, 0.2426], [To...   \n",
       "64621               2              [[Dom Dolla, 0.5869], [None, 0.4131]]   \n",
       "\n",
       "                                                    urls phase  \n",
       "24553  [https://nypost.com/2020/02/11/birds-of-prey-g...     E  \n",
       "30517  [https://www.politicshome.com/news/uk/health-a...     E  \n",
       "17456  [http://express.co.uk/news/politics/1236727/br...     E  \n",
       "98698  [http://www.noosanews.com.au/news/what-you-don...     E  \n",
       "64621  [https://musicfeeds.com.au/news/dom-dolla-has-...     E  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a single chunk to show how the data's layout\n",
    "for chunk in reader_2020:\n",
    "    df_0 = chunk\n",
    "    break\n",
    "\n",
    "# | quoteID | qotation | speaker | qids | date | numOccurrences | probas | urls | phase |\n",
    "df_0.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Load Speaker's Metadata from the parquet file***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.1 s, sys: 8.5 s, total: 30.6 s\n",
      "Wall time: 27.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# | aliases | date_of_bitrh | nationality | gender | lastrevid | ethnic_group | US_congress_bio_ID | occupation | party | academic_degree | id | label | candidacy | type | religion |\n",
    "df_parquet = pd.read_parquet(PARQUET_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet file shape: (9055981, 15)\n",
      "Are ids unique?   : True\n",
      "------------------------------\n",
      "Count:\n",
      "aliases               1203402\n",
      "date_of_birth         5017333\n",
      "nationality           3715852\n",
      "gender                7105600\n",
      "lastrevid             9055981\n",
      "ethnic_group           130385\n",
      "US_congress_bio_ID      12874\n",
      "occupation            6373084\n",
      "party                  399176\n",
      "academic_degree         99995\n",
      "id                    9055981\n",
      "label                 8543681\n",
      "candidacy               65442\n",
      "type                  9055981\n",
      "religion               196284\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f'Parquet file shape: {df_parquet.shape}',\n",
    "      f'Are ids unique?   : {df_parquet.id.nunique()==df_parquet.shape[0]}',\n",
    "      f'{\"-\"*30}',\n",
    "      'Count:',\n",
    "      df_parquet.count(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** The counts above are differents because for a given QID, there might not exist every metadata possible (*e.g.* an author might not belong to a political party)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Load the QID's of present instances in Quotebank*** \n",
    "\n",
    "It contains QID's of speakers, their gender, nationality and others if present. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 223 ms, sys: 84.2 ms, total: 307 ms\n",
      "Wall time: 328 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# | QID | Label | Description |\n",
    "df_qid = pd.read_csv(WIKIDATA_LABELS_FILE, compression='bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          QID  Label Description\n",
      "count   36969  32951       24542\n",
      "unique  36969  31462       17029\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8792</th>\n",
       "      <td>Q64504026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27418</th>\n",
       "      <td>Q84505214</td>\n",
       "      <td>East Asian studies scholar</td>\n",
       "      <td>scholar of East Asian studies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33963</th>\n",
       "      <td>Q2199864</td>\n",
       "      <td>duration</td>\n",
       "      <td>length of time of an event or process; quality...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7939</th>\n",
       "      <td>Q19610195</td>\n",
       "      <td>Candidate of Geography Sciences</td>\n",
       "      <td>higher doctoral degree in the Soviet Union and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             QID                            Label  \\\n",
       "8792   Q64504026                              NaN   \n",
       "27418  Q84505214       East Asian studies scholar   \n",
       "33963   Q2199864                         duration   \n",
       "7939   Q19610195  Candidate of Geography Sciences   \n",
       "\n",
       "                                             Description  \n",
       "8792                                                 NaN  \n",
       "27418                      scholar of East Asian studies  \n",
       "33963  length of time of an event or process; quality...  \n",
       "7939   higher doctoral degree in the Soviet Union and...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_qid.describe().loc[['count', 'unique']])\n",
    "df_qid.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that QID's are unique as expected, but not labels and descriptions which can also be non-defined (*i.e.* NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Defining different useful dataframes for our analysis***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the metadata from parquet where a gender is defined (i.e. not None)\n",
    "df_parquet_gender_noNa = df_parquet.dropna(subset=['gender'])\n",
    "\n",
    "# Creating lists of unique QID's for genders\n",
    "unique_gender_id, unique_speaker_index = helper.get_unique_list(df_parquet_gender_noNa.gender)\n",
    "speakers_gender_qid = pd.DataFrame({'qids': unique_gender_id}) # sometimes, there are many genders for a speaker -> consider all of them\n",
    "\n",
    "# Genders that are in parquet file and Quotebank\n",
    "df_gender = df_qid[df_qid.QID.isin(speakers_gender_qid.qids)]\n",
    "\n",
    "# Genders of speaker that are in Quotebank but NOT defined in the wikidata labels file\n",
    "df_gender_ko = speakers_gender_qid[-speakers_gender_qid.qids.isin(df_gender.QID)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='error1'></a>\n",
    "***Create a dataframe containing all unique genders present in Quotebank as indices, and the description of these genders according to the wikidata file, as well as the QID of the first speaker with the corresponding gender***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender_qids</th>\n",
       "      <th>speaker_qids</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender_names</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>--&gt; Not repertiored [1] ???</th>\n",
       "      <td>Q15145782</td>\n",
       "      <td>Q78971059</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--&gt; Not repertiored [2] ???</th>\n",
       "      <td>Q15145783</td>\n",
       "      <td>Q2078379</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Erkek</th>\n",
       "      <td>Q106299064</td>\n",
       "      <td>Q106375776</td>\n",
       "      <td>family name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gorō</th>\n",
       "      <td>Q8964773</td>\n",
       "      <td>Q1515301</td>\n",
       "      <td>male given name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taira no Kiyomori</th>\n",
       "      <td>Q281833</td>\n",
       "      <td>Q710537</td>\n",
       "      <td>Japanese samurai (1118-1181)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X-gender</th>\n",
       "      <td>Q96000630</td>\n",
       "      <td>Q2336456</td>\n",
       "      <td>a third gender or non-binary gender identity t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agender</th>\n",
       "      <td>Q505371</td>\n",
       "      <td>Q4754807</td>\n",
       "      <td>absence of a gender identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>androgyny</th>\n",
       "      <td>Q207959</td>\n",
       "      <td>Q66283650</td>\n",
       "      <td>combination of male and female traits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assigned female at birth</th>\n",
       "      <td>Q99485785</td>\n",
       "      <td>Q492190</td>\n",
       "      <td>gender identity assigned at birth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bigender</th>\n",
       "      <td>Q859614</td>\n",
       "      <td>Q89485952</td>\n",
       "      <td>gender identity that includes any two gender i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cisgender female</th>\n",
       "      <td>Q15145779</td>\n",
       "      <td>Q4769784</td>\n",
       "      <td>female person who was assigned female at birth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cisgender male</th>\n",
       "      <td>Q15145778</td>\n",
       "      <td>Q53866350</td>\n",
       "      <td>male person who was assigned male at birth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demiboy</th>\n",
       "      <td>Q93954933</td>\n",
       "      <td>Q63041986</td>\n",
       "      <td>gender identity where a person identifies as o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eunuch</th>\n",
       "      <td>Q179294</td>\n",
       "      <td>Q167105</td>\n",
       "      <td>castrated male human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>Q6581072</td>\n",
       "      <td>Q873</td>\n",
       "      <td>to be used in \"sex or gender\" (P21) to indicat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female organism</th>\n",
       "      <td>Q43445</td>\n",
       "      <td>Q106044198</td>\n",
       "      <td>plant or animal which is female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feminine</th>\n",
       "      <td>Q1775415</td>\n",
       "      <td>Q105908880</td>\n",
       "      <td>grammatical gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genderfluid</th>\n",
       "      <td>Q18116794</td>\n",
       "      <td>Q50825702</td>\n",
       "      <td>gender identity which doesn't conform to fixed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genderqueer</th>\n",
       "      <td>Q12964198</td>\n",
       "      <td>Q15838567</td>\n",
       "      <td>range of gender identities that are not exclus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>homosexuality</th>\n",
       "      <td>Q6636</td>\n",
       "      <td>Q106401950</td>\n",
       "      <td>romantic or sexual attraction or behavior betw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intersex</th>\n",
       "      <td>Q1097630</td>\n",
       "      <td>Q72636</td>\n",
       "      <td>innate variations in sex characteristics such ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kathoey</th>\n",
       "      <td>Q746411</td>\n",
       "      <td>Q105312093</td>\n",
       "      <td>third gender in Thai culture, usually transgen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>Q6581097</td>\n",
       "      <td>Q23</td>\n",
       "      <td>to be used in \"sex or gender\" (P21) to indicat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male organism</th>\n",
       "      <td>Q44148</td>\n",
       "      <td>Q104420311</td>\n",
       "      <td>for use with plants or non-human animals; use ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>muxe</th>\n",
       "      <td>Q3177577</td>\n",
       "      <td>Q98537077</td>\n",
       "      <td>Zapotec gender identity, often regarded as tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>māhū</th>\n",
       "      <td>Q3277905</td>\n",
       "      <td>Q18921903</td>\n",
       "      <td>third gender in traditional Hawaiian, Kanaka a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral sex</th>\n",
       "      <td>Q52261234</td>\n",
       "      <td>Q62571356</td>\n",
       "      <td>human who has neutral sex (use with Property:P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutrois</th>\n",
       "      <td>Q1289754</td>\n",
       "      <td>Q4685446</td>\n",
       "      <td>non-binary gender identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non-binary</th>\n",
       "      <td>Q48270</td>\n",
       "      <td>Q262772</td>\n",
       "      <td>range of gender identities that are not exclus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pangender</th>\n",
       "      <td>Q7130936</td>\n",
       "      <td>Q12349932</td>\n",
       "      <td>non-binary gender defined as being more than o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>queer</th>\n",
       "      <td>Q51415</td>\n",
       "      <td>Q105763839</td>\n",
       "      <td>umbrella term for sexual and gender minorities...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shemale</th>\n",
       "      <td>Q1984232</td>\n",
       "      <td>Q842633</td>\n",
       "      <td>term primarily used in sex work to describe a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third gender</th>\n",
       "      <td>Q48279</td>\n",
       "      <td>Q16191502</td>\n",
       "      <td>set of gender identities that are not exclusiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transfeminine</th>\n",
       "      <td>Q27679684</td>\n",
       "      <td>Q715027</td>\n",
       "      <td>gender of individuals who were assigned male a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transgender female</th>\n",
       "      <td>Q1052281</td>\n",
       "      <td>Q11625</td>\n",
       "      <td>female person who was assigned a different gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transgender male</th>\n",
       "      <td>Q2449503</td>\n",
       "      <td>Q213351</td>\n",
       "      <td>person assigned to the female sex at birth who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transgender person</th>\n",
       "      <td>Q189125</td>\n",
       "      <td>Q15906007</td>\n",
       "      <td>person whose gender identity is different from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transmasculine</th>\n",
       "      <td>Q27679766</td>\n",
       "      <td>Q29914316</td>\n",
       "      <td>gender of individuals who were assigned female...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two-spirit</th>\n",
       "      <td>Q301702</td>\n",
       "      <td>Q26252626</td>\n",
       "      <td>umbrella term for the third gender in the indi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            gender_qids speaker_qids  \\\n",
       "gender_names                                           \n",
       "--> Not repertiored [1] ???   Q15145782    Q78971059   \n",
       "--> Not repertiored [2] ???   Q15145783     Q2078379   \n",
       "Erkek                        Q106299064   Q106375776   \n",
       "Gorō                           Q8964773     Q1515301   \n",
       "Taira no Kiyomori               Q281833      Q710537   \n",
       "X-gender                      Q96000630     Q2336456   \n",
       "agender                         Q505371     Q4754807   \n",
       "androgyny                       Q207959    Q66283650   \n",
       "assigned female at birth      Q99485785      Q492190   \n",
       "bigender                        Q859614    Q89485952   \n",
       "cisgender female              Q15145779     Q4769784   \n",
       "cisgender male                Q15145778    Q53866350   \n",
       "demiboy                       Q93954933    Q63041986   \n",
       "eunuch                          Q179294      Q167105   \n",
       "female                         Q6581072         Q873   \n",
       "female organism                  Q43445   Q106044198   \n",
       "feminine                       Q1775415   Q105908880   \n",
       "genderfluid                   Q18116794    Q50825702   \n",
       "genderqueer                   Q12964198    Q15838567   \n",
       "homosexuality                     Q6636   Q106401950   \n",
       "intersex                       Q1097630       Q72636   \n",
       "kathoey                         Q746411   Q105312093   \n",
       "male                           Q6581097          Q23   \n",
       "male organism                    Q44148   Q104420311   \n",
       "muxe                           Q3177577    Q98537077   \n",
       "māhū                           Q3277905    Q18921903   \n",
       "neutral sex                   Q52261234    Q62571356   \n",
       "neutrois                       Q1289754     Q4685446   \n",
       "non-binary                       Q48270      Q262772   \n",
       "pangender                      Q7130936    Q12349932   \n",
       "queer                            Q51415   Q105763839   \n",
       "shemale                        Q1984232      Q842633   \n",
       "third gender                     Q48279    Q16191502   \n",
       "transfeminine                 Q27679684      Q715027   \n",
       "transgender female             Q1052281       Q11625   \n",
       "transgender male               Q2449503      Q213351   \n",
       "transgender person              Q189125    Q15906007   \n",
       "transmasculine                Q27679766    Q29914316   \n",
       "two-spirit                      Q301702    Q26252626   \n",
       "\n",
       "                                                                   description  \n",
       "gender_names                                                                    \n",
       "--> Not repertiored [1] ???                                                  -  \n",
       "--> Not repertiored [2] ???                                                  -  \n",
       "Erkek                                                              family name  \n",
       "Gorō                                                           male given name  \n",
       "Taira no Kiyomori                                 Japanese samurai (1118-1181)  \n",
       "X-gender                     a third gender or non-binary gender identity t...  \n",
       "agender                                           absence of a gender identity  \n",
       "androgyny                                combination of male and female traits  \n",
       "assigned female at birth                     gender identity assigned at birth  \n",
       "bigender                     gender identity that includes any two gender i...  \n",
       "cisgender female                female person who was assigned female at birth  \n",
       "cisgender male                      male person who was assigned male at birth  \n",
       "demiboy                      gender identity where a person identifies as o...  \n",
       "eunuch                                                    castrated male human  \n",
       "female                       to be used in \"sex or gender\" (P21) to indicat...  \n",
       "female organism                                plant or animal which is female  \n",
       "feminine                                                    grammatical gender  \n",
       "genderfluid                  gender identity which doesn't conform to fixed...  \n",
       "genderqueer                  range of gender identities that are not exclus...  \n",
       "homosexuality                romantic or sexual attraction or behavior betw...  \n",
       "intersex                     innate variations in sex characteristics such ...  \n",
       "kathoey                      third gender in Thai culture, usually transgen...  \n",
       "male                         to be used in \"sex or gender\" (P21) to indicat...  \n",
       "male organism                for use with plants or non-human animals; use ...  \n",
       "muxe                         Zapotec gender identity, often regarded as tra...  \n",
       "māhū                         third gender in traditional Hawaiian, Kanaka a...  \n",
       "neutral sex                  human who has neutral sex (use with Property:P...  \n",
       "neutrois                                            non-binary gender identity  \n",
       "non-binary                   range of gender identities that are not exclus...  \n",
       "pangender                    non-binary gender defined as being more than o...  \n",
       "queer                        umbrella term for sexual and gender minorities...  \n",
       "shemale                      term primarily used in sex work to describe a ...  \n",
       "third gender                 set of gender identities that are not exclusiv...  \n",
       "transfeminine                gender of individuals who were assigned male a...  \n",
       "transgender female           female person who was assigned a different gen...  \n",
       "transgender male             person assigned to the female sex at birth who...  \n",
       "transgender person           person whose gender identity is different from...  \n",
       "transmasculine               gender of individuals who were assigned female...  \n",
       "two-spirit                   umbrella term for the third gender in the indi...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_names, gender_qids, speaker_qids, gender_description = [], [], [], []\n",
    "count_not_rep = 0\n",
    "for i in unique_speaker_index:\n",
    "    for j in df_parquet_gender_noNa.gender.iloc[i]:\n",
    "        speaker_qids.append(df_parquet_gender_noNa.id.iloc[i])\n",
    "        gender_qids.append(j)\n",
    "        gender_name = df_qid[df_qid.QID == j].Label.values\n",
    "        if len(gender_name)>0:\n",
    "            gender_names.append(gender_name[0])\n",
    "            gender_description.append(df_qid[df_qid.QID == j].Description.values[0])\n",
    "        else:\n",
    "            count_not_rep += 1\n",
    "            gender_names.append(f'--> Not repertiored [{count_not_rep}] ???')\n",
    "            gender_description.append('-')\n",
    "\n",
    "df_gender_firstSpeaker = pd.DataFrame({'gender_names':gender_names, 'gender_qids':gender_qids, 'speaker_qids':speaker_qids, 'description': gender_description})\\\n",
    "                        .groupby('gender_names').agg('first')\n",
    "df_gender_firstSpeaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='error2'></a>\n",
    "**NOTE:** We can notice some irregularities in the data: some QID's considered as genders are not really genders.\n",
    "- **Queer, homosexuality:** Sexual orientation\n",
    "- **Erkek, Gorō:** Family Names\n",
    "- **Taira no Kiyomori:** Japanese Samurai\n",
    "- **Male/female organism:** Not really an irregularity but since speakers are human, it should not exist as a gender in the database\n",
    "\n",
    "There are also two QID's that correspond to transgender male/female when searching manually for them online, but they are not classified as such in the given wikidata file. A cause of this might be the fact that there already exists a QID for transgender males/females. Therefore, we will not drop them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***This is the main code for analysing a given year of Quotebank***\n",
    "\n",
    "We will count the number of quotations classified per gender and in time (per week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 1 has been processed in 10.33 [s]\n",
      "chunk 2 has been processed in 8.99 [s]\n",
      "chunk 3 has been processed in 11.21 [s]\n",
      "chunk 4 has been processed in 8.94 [s]\n",
      "chunk 5 has been processed in 9.65 [s]\n",
      "chunk 6 has been processed in 10.87 [s]\n",
      "chunk 7 has been processed in 7.58 [s]\n",
      "chunk 8 has been processed in 6.00 [s]\n",
      "chunk 9 has been processed in 9.20 [s]\n",
      "chunk 10 has been processed in 9.57 [s]\n",
      "chunk 11 has been processed in 9.85 [s]\n",
      "chunk 12 has been processed in 7.31 [s]\n",
      "chunk 13 has been processed in 7.52 [s]\n",
      "chunk 14 has been processed in 9.23 [s]\n",
      "chunk 15 has been processed in 7.07 [s]\n",
      "chunk 16 has been processed in 10.26 [s]\n",
      "chunk 17 has been processed in 8.30 [s]\n",
      "chunk 18 has been processed in 9.07 [s]\n",
      "chunk 19 has been processed in 8.99 [s]\n",
      "chunk 20 has been processed in 7.51 [s]\n",
      "chunk 21 has been processed in 8.65 [s]\n",
      "chunk 22 has been processed in 8.63 [s]\n",
      "chunk 23 has been processed in 9.28 [s]\n",
      "chunk 24 has been processed in 7.62 [s]\n",
      "chunk 25 has been processed in 9.16 [s]\n",
      "chunk 26 has been processed in 9.21 [s]\n",
      "chunk 27 has been processed in 8.15 [s]\n",
      "chunk 28 has been processed in 8.38 [s]\n",
      "chunk 29 has been processed in 7.94 [s]\n",
      "chunk 30 has been processed in 8.60 [s]\n",
      "chunk 31 has been processed in 7.40 [s]\n",
      "chunk 32 has been processed in 8.68 [s]\n",
      "chunk 33 has been processed in 6.93 [s]\n",
      "chunk 34 has been processed in 8.52 [s]\n",
      "chunk 35 has been processed in 8.41 [s]\n",
      "chunk 36 has been processed in 9.31 [s]\n",
      "chunk 37 has been processed in 8.41 [s]\n",
      "chunk 38 has been processed in 8.46 [s]\n",
      "chunk 39 has been processed in 8.19 [s]\n",
      "chunk 40 has been processed in 8.66 [s]\n",
      "chunk 41 has been processed in 8.89 [s]\n",
      "chunk 42 has been processed in 8.94 [s]\n",
      "chunk 43 has been processed in 8.50 [s]\n",
      "chunk 44 has been processed in 8.10 [s]\n",
      "chunk 45 has been processed in 8.28 [s]\n",
      "chunk 46 has been processed in 7.48 [s]\n",
      "chunk 47 has been processed in 9.42 [s]\n",
      "chunk 48 has been processed in 8.06 [s]\n",
      "chunk 49 has been processed in 8.57 [s]\n",
      "chunk 50 has been processed in 8.62 [s]\n",
      "chunk 51 has been processed in 9.11 [s]\n",
      "chunk 52 has been processed in 10.33 [s]\n",
      "chunk 53 has been processed in 5.72 [s]\n",
      "total time: 7.0 [min] and 36.09 [s]\n"
     ]
    }
   ],
   "source": [
    "# Reload the data to refresh the JsonReader (since it takes ~50µs to do so)\n",
    "reader_2020 = pd.read_json(QUOTES_FILE, lines=True, compression='bz2', chunksize=CHUNK_SIZE)\n",
    "\n",
    "count_male     = 0    # known speaker : men\n",
    "count_female   = 0    # known speaker : women\n",
    "count_others   = 0    # known speaker : other genders\n",
    "count_wrong    = 0    # known speaker : specified gender is not a gender\n",
    "count_noInfo   = 0    # known speaker : no info about gender\n",
    "count_noMeta   = 0    # known speaker : no metadata about speaker\n",
    "count_unknown  = 0    # unknown speaker\n",
    "count_all      = 0    # all quotations\n",
    "\n",
    "# list of Genders qid\n",
    "wrong_genders = ['Erkek', 'Gorō', 'Taira no Kiyomori', 'queer', 'homosexuality']\n",
    "\n",
    "qid_male    = [df_gender_firstSpeaker.loc['male'].gender_qids]\n",
    "qid_female  = [df_gender_firstSpeaker.loc['female'].gender_qids]\n",
    "qids_others = df_gender_firstSpeaker.drop(['male', 'female'] + wrong_genders)[['gender_qids']].gender_qids\n",
    "qids_wrong  = df_gender_firstSpeaker.loc[wrong_genders].gender_qids\n",
    "\n",
    "# Create dataframe to record weekly quotations per genders\n",
    "col      = ['male', 'female', 'others','wrong', 'noInfo', 'noMeta', 'unknown', 'all']\n",
    "index    = [i for i in range(1, 54)] # Represents 53 weeks (52 full + last incomplete)\n",
    "df_count = pd.DataFrame(0, index=index, columns=col)\n",
    "\n",
    "# DataFrame to record missing qids informations\n",
    "speaker_noMeta = pd.DataFrame()\n",
    "\n",
    "begin = time()\n",
    "chunk_begin = time()\n",
    "\n",
    "# Note: prefix of variables m_ resp. q_ means that we manipulate metadata resp. quotations\n",
    "for i, chunk in enumerate(reader_2020):\n",
    "    chunk['week']  = helper.get_week(chunk, 'quoteID')\n",
    "    \n",
    "    #_____\n",
    "    # ALL\n",
    "    #`````\n",
    "    count_all += chunk.shape[0]\n",
    "    df_count['all'] = df_count['all'].add(chunk.week.value_counts(), fill_value=0)\n",
    "\n",
    "    #________________\n",
    "    # SPEAKER UNKNOWN\n",
    "    #````````````````\n",
    "    # When there is an array of potential speakers, the 'speaker' column will contain the one with the highest probability. Sometimes, this speaker could be None.\n",
    "    #   --> if 1st is [None]: not kept\n",
    "    # \n",
    "    # When many QID's match a single name (homonyms): keep only the first QID \n",
    "    # (as we only have interest in gender, we assume that the true speaker and their homonyms share the same one)\n",
    "    q_is_speaker_known      = chunk.qids.apply(lambda x: bool(x))\n",
    "    q_speaker_known         = chunk[['week']][ q_is_speaker_known]\n",
    "    q_speaker_unknown       = chunk[['week']][-q_is_speaker_known]\n",
    "    q_speaker_known['qids'] = chunk[q_is_speaker_known].qids.apply(lambda x: x[0])\n",
    "    \n",
    "    df_count.unknown = df_count.unknown.add(q_speaker_unknown.week.value_counts(), fill_value=0)\n",
    "    count_unknown += chunk.shape[0]-q_speaker_known.shape[0]\n",
    "    \n",
    "    #________________\n",
    "    # SPEAKER NO META\n",
    "    #````````````````\n",
    "    m_is_speaker_known = df_parquet.id.isin(q_speaker_known.qids)\n",
    "    m_speaker_known    = df_parquet[m_is_speaker_known][['gender', 'id']]\n",
    "    \n",
    "    q_is_speaker_meta       = q_speaker_known.qids.isin(m_speaker_known.id)\n",
    "    q_speaker_known_no_meta = q_speaker_known[-q_is_speaker_meta]\n",
    "    q_speaker_known_meta    = q_speaker_known[ q_is_speaker_meta]\n",
    "    \n",
    "    df_count.noMeta = df_count.noMeta.add(q_speaker_known_no_meta.week.value_counts(), fill_value=0)\n",
    "    count_noMeta += q_speaker_known.shape[0]-q_speaker_known_meta.shape[0]\n",
    "    \n",
    "    # ID of known speakers without info\n",
    "    speaker_noMeta = speaker_noMeta.append(q_speaker_known_no_meta[['qids']].drop_duplicates())\n",
    "    \n",
    "    #________________\n",
    "    # GENDER NO INFO\n",
    "    #````````````````\n",
    "    m_is_gender_na = m_speaker_known.gender.isna()\n",
    "    m_gender_known = m_speaker_known[-m_is_gender_na]\n",
    "    q_is_gender_meta = q_speaker_known_meta.qids.isin(m_gender_known.id)\n",
    "    q_gender_no_meta = q_speaker_known_meta[-q_is_gender_meta]\n",
    "    q_gender_meta    = q_speaker_known_meta[ q_is_gender_meta]\n",
    "    \n",
    "    df_count.noInfo = df_count.noInfo.add(q_gender_no_meta.week.value_counts(), fill_value=0)\n",
    "    count_noInfo += q_speaker_known_meta.shape[0]-q_gender_meta.shape[0]\n",
    "    \n",
    "    #________________________\n",
    "    # MALE - FEMALE - OTHERS\n",
    "    #````````````````````````\n",
    "    # Gender Count : if two gender: Only the 1st one count, not the others   \n",
    "    m_is_male   = m_gender_known[m_gender_known.gender.apply(lambda x: x[0]).isin(qid_male)]\n",
    "    m_is_female = m_gender_known[m_gender_known.gender.apply(lambda x: x[0]).isin(qid_female)]\n",
    "    m_is_others = m_gender_known[m_gender_known.gender.apply(lambda x: x[0]).isin(qids_others)]\n",
    "    m_is_wrong  = m_gender_known[m_gender_known.gender.apply(lambda x: x[0]).isin(qids_wrong)]\n",
    "    \n",
    "    q_gender_meta_male   = q_gender_meta[q_gender_meta.qids.isin(m_is_male.id)]\n",
    "    q_gender_meta_female = q_gender_meta[q_gender_meta.qids.isin(m_is_female.id)]\n",
    "    q_gender_meta_others = q_gender_meta[q_gender_meta.qids.isin(m_is_others.id)]\n",
    "    q_gender_meta_wrong  = q_gender_meta[q_gender_meta.qids.isin(m_is_wrong.id)]    \n",
    "    \n",
    "    df_count.male   = df_count.male.add(q_gender_meta_male.week.value_counts(), fill_value=0)\n",
    "    df_count.female = df_count.female.add(q_gender_meta_female.week.value_counts(), fill_value=0)\n",
    "    df_count.others = df_count.others.add(q_gender_meta_others.week.value_counts(), fill_value=0)\n",
    "    df_count.wrong  = df_count.wrong.add(q_gender_meta_wrong.week.value_counts(), fill_value=0)\n",
    "\n",
    "    count_male   += q_gender_meta_male.shape[0]\n",
    "    count_female += q_gender_meta_female.shape[0]\n",
    "    count_others += q_gender_meta_others.shape[0]\n",
    "    count_wrong  += q_gender_meta_wrong.shape[0]\n",
    "    \n",
    "    \n",
    "    print(f'chunk {i+1} has been processed in {(time()-chunk_begin):.2f} [s]')\n",
    "    chunk_begin = time() # Reset timer for next chunk\n",
    "    \n",
    "print(f'total time: {(time() - begin)//60} [min] and {(time()-begin)%60:.2f} [s]')\n",
    "\n",
    "#_____________\n",
    "# TOTAL COUNT\n",
    "#`````````````\n",
    "df_count.loc['sum'] = df_count.sum()\n",
    "df_count = df_count.astype(int)\n",
    "\n",
    "# might have same unknown in different chunk\n",
    "speaker_noMeta = speaker_noMeta.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "known writer   | men                  | 2726294\n",
      "known writer   | women                | 648408\n",
      "known writer   | other gender         | 6655\n",
      "known writer   | wrong gender         | 0\n",
      "known writer   | no info about sex    | 40506\n",
      "known writer   | no meta about writer | 21742\n",
      "unknown writer |                        1800844\n",
      "all            |                        5244449\n",
      "Checksum: OK\n"
     ]
    }
   ],
   "source": [
    "total = count_male+count_female+count_others + \\\n",
    "    count_wrong+count_noInfo+count_noMeta+count_unknown\n",
    "print(f'known writer   | men                  | {count_male}',\n",
    "      f'known writer   | women                | {count_female}',\n",
    "      f'known writer   | other gender         | {count_others}',\n",
    "      f'known writer   | wrong gender         | {count_wrong}',\n",
    "      f'known writer   | no info about sex    | {count_noInfo}',\n",
    "      f'known writer   | no meta about writer | {count_noMeta}',\n",
    "      f'unknown writer |                        {count_unknown}',\n",
    "      f'all            |                        {count_all}',\n",
    "      f'''Checksum: {\"OK\" if total == count_all \n",
    "                            else f\"Error while processing : sum= {total} != {count_all}\"}''',\n",
    "      sep='\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** there are 0 wrong genders which might seem strange since we said that Quotebank contained those. But this also could be expected, because when considering only the first gender in the QID's array, the less important genders are dropped.\n",
    "\n",
    "*Example:* Consider an imaginary quote from Samurai Jack, we would get as genders `['male', 'samurai']` but our code only takes into account `'male'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Results of previous 2 cells***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>others</th>\n",
       "      <th>wrong</th>\n",
       "      <th>noInfo</th>\n",
       "      <th>noMeta</th>\n",
       "      <th>unknown</th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96028</td>\n",
       "      <td>19436</td>\n",
       "      <td>303</td>\n",
       "      <td>0</td>\n",
       "      <td>1130</td>\n",
       "      <td>702</td>\n",
       "      <td>64049</td>\n",
       "      <td>181648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>194593</td>\n",
       "      <td>45089</td>\n",
       "      <td>411</td>\n",
       "      <td>0</td>\n",
       "      <td>2704</td>\n",
       "      <td>1385</td>\n",
       "      <td>133990</td>\n",
       "      <td>378172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>205254</td>\n",
       "      <td>48481</td>\n",
       "      <td>550</td>\n",
       "      <td>0</td>\n",
       "      <td>2736</td>\n",
       "      <td>1542</td>\n",
       "      <td>142719</td>\n",
       "      <td>401282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>209436</td>\n",
       "      <td>51474</td>\n",
       "      <td>469</td>\n",
       "      <td>0</td>\n",
       "      <td>3137</td>\n",
       "      <td>1590</td>\n",
       "      <td>141938</td>\n",
       "      <td>408044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>224486</td>\n",
       "      <td>53239</td>\n",
       "      <td>488</td>\n",
       "      <td>0</td>\n",
       "      <td>3077</td>\n",
       "      <td>1812</td>\n",
       "      <td>155928</td>\n",
       "      <td>439030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>220281</td>\n",
       "      <td>56340</td>\n",
       "      <td>367</td>\n",
       "      <td>0</td>\n",
       "      <td>3250</td>\n",
       "      <td>1603</td>\n",
       "      <td>153498</td>\n",
       "      <td>435339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>220762</td>\n",
       "      <td>52981</td>\n",
       "      <td>606</td>\n",
       "      <td>0</td>\n",
       "      <td>3137</td>\n",
       "      <td>1710</td>\n",
       "      <td>152372</td>\n",
       "      <td>431568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>180934</td>\n",
       "      <td>42583</td>\n",
       "      <td>392</td>\n",
       "      <td>0</td>\n",
       "      <td>2580</td>\n",
       "      <td>1344</td>\n",
       "      <td>123713</td>\n",
       "      <td>351546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>173946</td>\n",
       "      <td>38841</td>\n",
       "      <td>377</td>\n",
       "      <td>0</td>\n",
       "      <td>2644</td>\n",
       "      <td>1480</td>\n",
       "      <td>115601</td>\n",
       "      <td>332889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>157259</td>\n",
       "      <td>40835</td>\n",
       "      <td>321</td>\n",
       "      <td>0</td>\n",
       "      <td>2428</td>\n",
       "      <td>1250</td>\n",
       "      <td>105393</td>\n",
       "      <td>307486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>160556</td>\n",
       "      <td>37060</td>\n",
       "      <td>448</td>\n",
       "      <td>0</td>\n",
       "      <td>2560</td>\n",
       "      <td>1318</td>\n",
       "      <td>105607</td>\n",
       "      <td>307549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>163601</td>\n",
       "      <td>38434</td>\n",
       "      <td>492</td>\n",
       "      <td>0</td>\n",
       "      <td>2516</td>\n",
       "      <td>1423</td>\n",
       "      <td>100384</td>\n",
       "      <td>306850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>156094</td>\n",
       "      <td>37076</td>\n",
       "      <td>568</td>\n",
       "      <td>0</td>\n",
       "      <td>2431</td>\n",
       "      <td>1391</td>\n",
       "      <td>92278</td>\n",
       "      <td>289838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>144000</td>\n",
       "      <td>34199</td>\n",
       "      <td>402</td>\n",
       "      <td>0</td>\n",
       "      <td>2518</td>\n",
       "      <td>1298</td>\n",
       "      <td>84930</td>\n",
       "      <td>267347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>130337</td>\n",
       "      <td>30265</td>\n",
       "      <td>245</td>\n",
       "      <td>0</td>\n",
       "      <td>2194</td>\n",
       "      <td>1014</td>\n",
       "      <td>75765</td>\n",
       "      <td>239820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>88727</td>\n",
       "      <td>22075</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>1464</td>\n",
       "      <td>880</td>\n",
       "      <td>52679</td>\n",
       "      <td>166041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>2726294</td>\n",
       "      <td>648408</td>\n",
       "      <td>6655</td>\n",
       "      <td>0</td>\n",
       "      <td>40506</td>\n",
       "      <td>21742</td>\n",
       "      <td>1800844</td>\n",
       "      <td>5244449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        male  female  others  wrong  noInfo  noMeta  unknown      all\n",
       "1      96028   19436     303      0    1130     702    64049   181648\n",
       "2     194593   45089     411      0    2704    1385   133990   378172\n",
       "3     205254   48481     550      0    2736    1542   142719   401282\n",
       "4     209436   51474     469      0    3137    1590   141938   408044\n",
       "5     224486   53239     488      0    3077    1812   155928   439030\n",
       "6     220281   56340     367      0    3250    1603   153498   435339\n",
       "7     220762   52981     606      0    3137    1710   152372   431568\n",
       "8     180934   42583     392      0    2580    1344   123713   351546\n",
       "9     173946   38841     377      0    2644    1480   115601   332889\n",
       "10    157259   40835     321      0    2428    1250   105393   307486\n",
       "11    160556   37060     448      0    2560    1318   105607   307549\n",
       "12    163601   38434     492      0    2516    1423   100384   306850\n",
       "13    156094   37076     568      0    2431    1391    92278   289838\n",
       "14    144000   34199     402      0    2518    1298    84930   267347\n",
       "15    130337   30265     245      0    2194    1014    75765   239820\n",
       "16     88727   22075     216      0    1464     880    52679   166041\n",
       "17         0       0       0      0       0       0        0        0\n",
       "18         0       0       0      0       0       0        0        0\n",
       "19         0       0       0      0       0       0        0        0\n",
       "20         0       0       0      0       0       0        0        0\n",
       "21         0       0       0      0       0       0        0        0\n",
       "22         0       0       0      0       0       0        0        0\n",
       "23         0       0       0      0       0       0        0        0\n",
       "24         0       0       0      0       0       0        0        0\n",
       "25         0       0       0      0       0       0        0        0\n",
       "26         0       0       0      0       0       0        0        0\n",
       "27         0       0       0      0       0       0        0        0\n",
       "28         0       0       0      0       0       0        0        0\n",
       "29         0       0       0      0       0       0        0        0\n",
       "30         0       0       0      0       0       0        0        0\n",
       "31         0       0       0      0       0       0        0        0\n",
       "32         0       0       0      0       0       0        0        0\n",
       "33         0       0       0      0       0       0        0        0\n",
       "34         0       0       0      0       0       0        0        0\n",
       "35         0       0       0      0       0       0        0        0\n",
       "36         0       0       0      0       0       0        0        0\n",
       "37         0       0       0      0       0       0        0        0\n",
       "38         0       0       0      0       0       0        0        0\n",
       "39         0       0       0      0       0       0        0        0\n",
       "40         0       0       0      0       0       0        0        0\n",
       "41         0       0       0      0       0       0        0        0\n",
       "42         0       0       0      0       0       0        0        0\n",
       "43         0       0       0      0       0       0        0        0\n",
       "44         0       0       0      0       0       0        0        0\n",
       "45         0       0       0      0       0       0        0        0\n",
       "46         0       0       0      0       0       0        0        0\n",
       "47         0       0       0      0       0       0        0        0\n",
       "48         0       0       0      0       0       0        0        0\n",
       "49         0       0       0      0       0       0        0        0\n",
       "50         0       0       0      0       0       0        0        0\n",
       "51         0       0       0      0       0       0        0        0\n",
       "52         0       0       0      0       0       0        0        0\n",
       "53         0       0       0      0       0       0        0        0\n",
       "sum  2726294  648408    6655      0   40506   21742  1800844  5244449"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There aren't any quotes after week 16. This comes from the fact that the Quotebank dataset stopped analysing quotes until April 2020 (see [Quotebank paper](https://dlab.epfl.ch/people/west/pub/Vaucher-Spitz-Catasta-West_WSDM-21.pdf)). This is not the case for previous years as we have seen in our analysis, or as the TA's might see if they decide to run our notebook with the full years `[2015;2020]`\n",
    "\n",
    "We also can output that the last month was april from the following code which would take ~5 mins to complete\n",
    "```python\n",
    "df_20 = pd.read_json(PATH_DATA+FILE_20, lines=True, compression='bz2', chunksize=CHUNK_SIZE)\n",
    "max_month = -1\n",
    "for chunk in df_20:\n",
    "    chunk['month'] = get_month(chunk, 'quoteID').astype(int)\n",
    "    month = chunk.month.max()\n",
    "    if month>max_month:\n",
    "        max_month = month\n",
    "\n",
    "print(f'max month in 2020 is: {max_month}')\n",
    "```\n",
    "> out: max month in 2020 is: 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb4AAAEWCAYAAAAZwvJqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAs/0lEQVR4nO3dedxUdfn/8dfFKiCLgpaACoUroWW3kOaCS4ELopY/LSs1E/c09GumqZhaWaaWZYqJiLu4giulgrsoKgrigkiCG6BwI7gEev3++HwGhmHmXpjPzcw9834+HvfjnjnnzDXXnO2a8zmfOcfcHRERkWrRotQJiIiIrE0qfCIiUlVU+EREpKqo8ImISFVR4RMRkaqiwiciIlWlogufmR1qZhPW0nv1MjM3s1ZNFN/NrE98fIWZnZUo7iZmtsTMWsbnE83sFylix3j3m9lhqeI14n3PN7MFZvb+2n7v5sbMZpvZnqXOQ1Zq6v1JJTGz0WZ2fmNe06DCZ2Y/NrPn4g7yvbgz22nN0lx73P0Gd/9+U8Qu5c7C3Y9x9/Pqm64hObr72+6+rrt/UWxeZjbCzK7Pib+Xu19bbOxG5rExcAqwtbt/dS2/d9IvDiKSXr2Fz8yGA5cCvwe+AmwCXA4MbdLMiqRvSvWr4Hm0KfChu88rdSLVooLXpWanVMuiWa0D7l7wD+gMLAEOqmOatoTC+G78uxRoG8cNBOYCpwHzgPeA/YG9gdeBj4AzsmKNAG4DbgE+Bp4Hts0afzrwZhz3CnBA1rjDgSeAS2Lc8+Owx7OmceAY4A1gIfAPwOK4lsBfgAXAW8AJcfpWeT7zdcCXwKdx/pwG9IrTHwa8HeOcmfWaFln5fwjcCqxfx3z9vzi/3gV+HmP3ieNGA+fHx92Ae4BF8XM/Ft+rrhyPjDk+mjWsVYw3EfgDMBmoBe7O5JlZnjl5zgb2BAYD/wOWxfebmhXvF1nz4LfAfwnrwxigcxxX5/wrsG6OAebHeL+N8feMn/nLmMfoNZi/K3LOWrey16MdgWfj/HkW2DEOvwD4Avgsvvff4/AtgX/H5fMa8P/q+FyHA7MI6/hbwKE56/dl8X1fBfbImR9Xx8/0DmH9bxnHfR14mLDeLQBuALrkLsOsXN8CDonP9wVeJKxfTwLb5Lzu18BLwOdAq/j8nZj/a9k55nzOfYAXgMXAHGBE1rjMunBEHLeQsN1uH99rUWbeFrteAe2Aa+N7zCBsJ3PrWD7fj5+rlnAAMClnXfl5jLMQeBDYtBH7n4tifrOA41l1u6xr+WbWjex9X5+YW22MeUuBz5OZP8MI28J7wCkN2W+RZ3+SJ/4k4Afx8U5x+r3j8z2BFxs47wpuQ6y6P+wIPAL8LTNv837uQiNikMHAcvLs/LOm+R3wNLAhsAFh4zgva0e5HDgbaA0cRdhR3RgT7EvYSXwtTj+CsOP8YZz+VMJG2DqOPwjoHhfGwcBSYKOshb8cOJGwAbYjf+G7B+hCOHKdDwyO444hFNOewHrAfyhQ+HJ3FjkrwVXxvbcl7Ay2iuNPjvOpJ+HLwpXATXXM9w+AbwAd4vwqVPj+AFwR51drYGdWbkyFchwT47Yjf+F7J+u9bweuz1qeeQtf1vK7Pmf8RFYWvp8DM4GvAesCdwDXNWT+5ZlHYwhFuWN87evAkYXybOT8XZFz1rr1eHy8PmHD/ClhPftRfN61wGs7EHbeR8TptyPsiPrmyasDoRBsEZ9vlJmOlev3r+JyPpiwU8vshO4irFMdCNviZODoOK4P8D3CercB4QvPpbnLMOb2NrBvHL4doZAMIOyYD4vTts163YvAxnGZbRE/a/esZfr1AstgINCPsC1vE5fH/jnrwhXAOoRi81n8jBsCPWJeuxa7XgF/JOyc1yNsmy9RYN0hfMlcDBwYl+VJhP1VZv3eP+axVRz/W+DJRux/Xo3zcn3Czjt7u6xr+R7O6vu+m4Az4/xdB9ipwGfKzJ+bYux+Ma/MNn0yBfZb5NmfFKgPl8XHZxAK6IVZ4/5a37yjnm2IuD8Eusb5cn5dda0hhe9Q4P16pnmTWMHj80HA7KyV+1NWfjPpGGfUgKzpp7ByhR8BPJ01rgXhG8jOBd77RWBo1sJ/O2f84axe+HbKen4rcHp8/HBmRYrP92TNCl/PrGGTWfnNeQarfkPfiLDR5DuiHAX8Mev55hQufL8jFIA+jcjxa3mGZRe+7PfemnAk15LiC99DwHFZ47bIzIP65l9OzJaEndfWWcOOBiZmrXd1Fb765u+KnHPXI0LBm5wT7yng8AKvPRh4LGf6K4Fz8uTVgXA08wNydiIxh3fJ+hYb589PCacgPs9+DaEgP1Lg8+8PvJCzDM8ltM7sljX8n8QvsVnDXmNlwZkN/DxrXB9CQdqT+GW1oX+ElqJLctbJHlnjPwQOznp+O3BysesV4ehqUNa4XxRad4CfAU9lPTfCDjmzft9P/PIVn7cAPiEeuVD//ueYrHHfj9O3qm/5kn/fNwYYmf25C3ymzPzZMmvYn4Cr4+OC+y3y7E/yxN8DeCk+fiDO36fj80nAgfXNO+rZhgj7w1HANOD/GrK+1XeO70OgWz1tt90JTQwZ/43DVsTwlR0nPo3/P8ga/ynhW1rGnMwDd/+SsDF2BzCzn5nZi2a2yMwWEb6xd8v32jpk9/L7JOu9u+e8viGxGhN/U+DOrNxnEJrFvpInRm4u/80zTcafCd+UJpjZLDM7vQE51vfZct+7NavO5zWVb13JbNgZheZftm5AmzyxejQij4bO33yvzZ2+rvfeFBiQWe5x2R8KrNbpxt2XEjbyY4D3zOxeM9sya5J3PG7pWe/bPb5H6/iazHtcSTgywMw2NLObzewdM1sMXM/qy/MYwjfsR3JyPyUn941ZdfvO3l5nEo4QRgDz4ntmT7uCmQ0ws0fMbL6Z1cb3z80pdz9RaL9RzHrVmO1+lWnjspibNX5T4K9Z8+ojQnHMXjcamkf256lz+RbI+7T43pPNbLqZ/byOz5X7+ux9eEP2W3XNs6eAzc3sK8A3CQV5YzPrBvQntD5k3qfQvGvINrQP4Uj3ino+J1B/55anCE0M+9cxzbsxsYxN4rA1tXHmgZm1IBxiv2tmmxKaK04gNCt1IVR4y3pt9k6hsd6L77VaHgU09r3mAHu5e5esv3Xc/Z0CuWS//yYFk3D/2N1PcfevAUOA4Wa2Rz051pd77nsvIzQtLAXaZ0bEn0Bs0Ii4+daV5ay6Q2uIBTGn3Fj55mU+9c3fVT4nq25guZ8h971z58EcYFLOcl/X3Y/Nl5i7P+ju3yN8s36VsM5n9DCz7PU9s63NIRwRdMt6j07u3jdO94eY1zbu3gn4CatuNxAKzyZmdklO7hfk5N7e3W/KTjkn/xvdfSfCPHLgwnyfk9C8PA7Y2N07E3ZYuTk1VDHrVWO2+1Wmjcsi+7VzCK1G2fOrnbs/2cA8Cq2T9S1fWH05vO/uR7l7d0JryOWZn0MVkPvemX14Q/ZbBbd7d/+E0Kp3EjDN3f9HOB02HHjT3RdkvU+hedeQbegqwhHlfWbWoY7PCdRT+Ny9lnB+7h9mtr+ZtTez1ma2l5n9KU52E/BbM9sgVvGzCd8o19S3zezAeJR5MmGBP01oBnJC+zNmdgThiC+VW4GTzKyHmXUhnKSvyweEcwoNdQVwQSzgxPk1tI5cDjezrc2sPXBOoaBmtq+Z9Ykb4WLCt7HMEXZjc8z4SdZ7/w64LR61vw6sY2b7mFlrQjt826zXfQD0il9Y8rkJ+JWZ9TazdQk9hW9x9+WNSS7mcithfnaM83Q4DV/v6pu/LwIHxvW9D+HkfcZ9hG+wPzazVmZ2MKE5+J44Pnee3xOn/2ncdlqb2fZmtlVuUmb2FTPbL264nxM6yGT/zGRD4JcxxkGE8yH3uft7wATgL2bWycxamNnXzWzX+LqOMdYiM+tB6NiT62PCuc9dzOyPcdhVwDHx6MzMrENc9h3zzVQz28LMdjeztoQvzJ/m5J+tI/CRu39mZv2BHxeYriGKWa9uBX5jZuvFeXNCHdPeC/SL+8JWhA4o2V+Kroix+gKYWee4nBriVsKy7Wlm6xE6lADQgOW7GjM7yMwyRXkhYd9Z10+Wzorre1/CubRbsj5TQ/dbhUwizNdJ8fnEnOeZ9yk07xq6DZ1AaIq/x8za1ZVQvT9ncPeLCTuV3xKKzpz4BnfFSc4HniOcFH6Z0BOzUT8mzHE3oblnIeH8xYHuvszdXyH0unyKsHPpR+jJlMpVhJXrJUJvs/sI3xoLrSx/IBT8RWZ2agPi/5XwDXeCmX1MKOYD8k3o7vcTznk8TGjGfLiOuJsROuIsIcyby9194hrmmHEdod38fcKJ8V/GvGqB44B/EY5wlrJqU8/Y+P9DM3s+T9xRMfajhE5LnxFOyK+JE+P7zwIeJxxBjGrICxswfy8hnNf8gNDj74as135I6Ol4CuFUwGmEziCZb65/BX5oZgvN7G/u/jHhfM0hhG/R7xOOgrK/MGS0iHHfJTT17EqY3xnPEJb3AkIP0h/GfCCcf2pD6KC1kNA7eqM47lxCh4Baws77jgLzZRGhE8xeZnaeuz9H6JD29xhzJuF8UiFtCZ1FFsTPuSGhQ0M+xwG/i9vC2YQd/5oqZr36HWEdfouwHd1G+NKxmriMDyKcA/uQ8IXnucz07n4nYdnebKFJeRqwVwPzuIrQk3EqYR+au4zqWr75bA88Y2ZLCPudk9z9rTqmn0RYvg8BF7l75sIfDd5v1RO7IyubNXOf1znvGroNxabnYYQadbeZrVMooUzvv7JgZiMIHQx+Uga57AVc4e65zVpSgczMgc3ieaqyY2aHEzpRlP2FI5ozMzuW0PGl4NFU1rQtCEXz0Jxzo82GmfViZc/5RrW8NGcVfcmyxjCzdma2d2y+6kFo/rqz1HmJSNMxs43M7Lux+XALwhF3we3ezAaZWZfYnHsG4bzk02spXUlEhW8lIzQJLSQ0dc4gNMGISOVqQ+gh+TGhyftuwg/TC9mB8BOuBYTOZPu7+6d1TC9lqKyaOkVERJqajvhERKSqNJ+Liq6hbt26ea9evUqdhohIszJlypQF7r5B/VM2PxVf+Hr16sVzzz1X6jRERJoVM2vMFY2alYpt6jSzIWY2sra2ttSpiIhIGanYwufu4919WOfOnUudioiIlJGKLXwiIiL5VPw5PhERgGXLljF37lw+++yzUqdSVtZZZx169uxJ69atS53KWqPCJyJVYe7cuXTs2JFevXphtqY3gqgs7s6HH37I3Llz6d27d6nTWWvU1CkiVeGzzz6ja9euKnpZzIyuXbtW3VGwCp+IVA0VvdVV4zxR4RMRkaqic3yyRu6dPruo1+/Tt1eSPETWVLHrcK6mXqcnTpzIRRddxD333FP/xFInFT4pG01RTFWgRSSXCl8VSPHNVgVApHizZ89m8ODB7LTTTjz99NNsu+22HHHEEZxzzjnMmzePG264AYCTTz6ZTz/9lHbt2nHNNdewxRZbrBJn6dKlnHjiibz88sssX76cESNGMHTo0FJ8pGZJha/MqEiJVLaZM2cyduxYRo4cyfbbb8+NN97I448/zrhx4/j973/PmDFjePTRR2nVqhX/+c9/OOOMM7j99ttXiXHBBRew++67M2rUKBYtWkT//v3Zc8896dChQ4k+VfNSsYXPzIYAQ/r06dNk76EiJSKN1bt3b/r16wdA37592WOPPTAz+vXrx+zZs6mtreWwww7jjTfewMxYtmzZajEmTJjAuHHjuOiii4DwU423336brbbaaq1+luaqYgufu48HxtfU1BxV6lxERDLatm274nGLFi1WPG/RogXLly/nrLPOYrfdduPOO+9k9uzZDBw4cLUY7s7tt9++WhOoNEzFFj6RpqCjfGlqtbW19OjRA4DRo0fnnWbQoEFcdtllXHbZZZgZL7zwAt/61rfWYpbNmwqfiFSlcv0Cctppp3HYYYdx8cUXs/vuu+ed5qyzzuLkk09mm222wd3p1auXfubQCCp8IiWmo8jq0atXL6ZNm7biefYRXfa4119/fcXw8847D4CBAweuaPZs164dV155ZdMnXKFU+ESkZFT0pRRU+EQqUFMUFBUpqRQqfCJSUQoV6I2+WM6iTz9vUIwu7drWP5E0W7pItYiIVBUd8YmI1KOhR4p10VFk+dARn4iIVBUd8YlIVWr7zAsFx32aO20D4n0+oP4fkP/tb3/jn//8J9ttt92KC1KnNGLECNZdd11OPfXU5LEriQqfiMhacvnll3P//ffTu3dvNZ+WkAqfiMhacMwxxzBr1iz2228/DjnkEGa89jqvTJ/O8uXLOf3M37L3kCHceN0Y7h0/ni+++IIZr0zn+F+ezLJl/+OWG2+kbdu23HrnXay3/vpcO+pqrh01ii+WL6NPnz5cd911tG/ffpX3e/PNNzn++OOZP38+7du356qrrmLLLbcs0acvLzrHJyKyFlxxxRV0796dRx55hKVLl7LzwIE8/PgTjH/gQc4+8zcsXboUgBmvTOeq0dfy0KOPc/6559CuXXseffoZth8wgJtvDM2jQ4buz8OPP8HUqVPZaqutuPrqq1d7v2HDhnHZZZcxZcoULrroIo477ri1+nnLmY74RETWsgkTJrD07rv5+6WXAuG2QnPnzAFg5112pWPHjnTs2JFOnToxeO+9Adi6b1+mx0uazXhlOuefO4IlixezZMkSBg0atEr8JUuW8OSTT3LQQQetGPb558U3rVaKZlX4zGwgcB4wHbjZ3SeWMh8RkTXh7oy58WY223zzVYZPeXYybeq5bRHAccOO4vpbxrLzgO0ZPXo0EydOXCXOl19+SZcuXXjxxReb9HM0VyVv6jSzUWY2z8ym5QwfbGavmdlMMzs9DnZgCbAOMHdt5yoiksKgQYMY+c/LcXcAXmpkgVqyZAlf/epXWbZsWd7eoZ06daJ3796MHTsWCIV26tSpReddKcrhiG808HdgTGaAmbUE/gF8j1DgnjWzccBj7j7JzL4CXAwcuvbTFZFKUNfPD3J7S6bogZntrLPO4tgTTuS7/WtwdzbZZFNuuePOBr/+jLPOYc9dd6Z3r17069ePjz/+eLVpbrjhBo499ljOP/98li1bxiGHHMK2226b8mM0WyUvfO7+qJn1yhncH5jp7rMAzOxmYKi7vxLHL6SOn9aY2TBgGMAmm2ySPGcRkTUxe/bsFY8v/fs/Vhv/45/+jB//9Gcrnr/06ut5xx05bBhHDhu2WoEeMWLEise9e/fmgQceSJR5ZSl54SugBzAn6/lcYICZHQgMAroQjhLzcveRwEiAmpoaB11ZXkREgnItfJZnmLv7HcAdazsZERGpHCXv3FLAXGDjrOc9gXcbE8DMhpjZyNra2qSJiYhI81auR3zPApuZWW/gHeAQ4MeNCeDu44HxNTU1RzVBfiIiZWdNO+F8umz5itNB1XBKp+RHfGZ2E/AUsIWZzTWzI919OXAC8CAwA7jV3aeXMk8REakMJT/ic/cfFRh+H3DfWk5HREQqXMkLX1MxsyHAkD59+pQ6FREpQ8tGjy04bv4axGt9+EH1T5RH7aJFjL3lFn5x9NEAPP7oJC679NJG/a5PGqfkTZ1Nxd3Hu/uwzp07lzoVEZGCamsXcfVVVyaLl7msmRRWsUd8IiLl6OKLL2bUqFF84c7PDj+CZydPZvasWew8oD8D99iDQYMHs3TpEg778Y+Y8cp0tv3Wtxg5ajRmxovPP8+Zp5/G0iVL6dqtK9ePGcNGG23EwIED2XHHHZn02GPstc++9Nx4Yy78/QW0bNmSTp06cd+/Hyr1xy4rFVv41NQpIuVmypQpXHPNNTzzzDMs/OQzvrfrzlx59TXMeGU6jz0zGQhNnS9NncpTzz3PRt27M3j33Xj6qSep2b4/p50ynBtvHUu3DTbgjtvGcuaZZzJq1CgAFi1axL0T/gPAjtt/m9vvHk/3Hj2oXbSoVB+3bFVs4dPPGUSk3Dz++OMccMABdOjQgWUtWrHvfkN56sknVpvu2zU19OjZE4BvbLMNb//3v3Tu3IVXX5nOAfvuA8AXX35Bz+7dV7zm4IMPXvF4wHd24Pijj2L/A3/AkKH7N+2HaoYqtvCJiJSbzN0Y6tOmzcprcLZs2ZIvli/H3dlyq62ZMHHSinHZ1+rs0KHDiseXXPZ3nps8mQkP3M/O3+nPY09PZv2uXRN8gspQsZ1bRETKzS677MJdd93FJ598wtKlS7ln/DgGfGcHluS5u0KuzTbfnAUL5jP5macBWLZsGdOn5/9581uz3qSmf3/OOPscunbtxjtzdRe3bDriE5GqVNfPD5rqtkTbbbcdhx9+OP3791/RueWb223HgB12YIea7djz+4MYNHhw3te2adOGa2+4iV+fOpzFixfzxfLlDP/Vr+jbt+9q0559xhm8+eZM3J1dB+7GN7bZJkn+laJiC586t4hIORo+fDjDhw9fpZj+a/SYVabZaZddVzz+8yWXrnjcb9ttV+mhmSnQmTuwZ2Jed/MtqdOuKBXb1Knf8YmISD4Ve8Qnzc/u898vMkKvFGmISIVT4ZM10lyKVHPJU5qeE3pVmuW73Wf1cnca1te0cqjwVYHid/6gAiDN3TJasHjRQjp1WU/FL3J3Fi9ayLLKPeuVV8UWPnVuEZFsC1u0gwUfsWDBAuore+1ar7pr/HRZ8de/LMeYTvhCsLBFu6JzaU4qtvA11yu36OhMpGl8aS34sGWH+icE9tmq1yrPMzdpLUZziVkNquv4VkREql7FHvGtDTo6ExFpfnTEJyIiVUVHfCKNoKN8keavYgufenVKNVOBFimsYgtfc+3VKdWnmotUNX92KZ2KLXwiUp1UTKU+Knwi0iAqKFIp1KtTRESqio74RETqoaPdyqIjPhERqSpJCp+ZdTCzFvHx5ma2n5m1ThFbREQkpVRNnY8CO5vZesBDwHPAwcChieKLiFQUNZ+WTqqmTnP3T4ADgcvc/QBg60Sx1ywhsyFmNrK2traUaYiISJlJVvjMbAfCEd69cVhJO864+3h3H9a5c+dSpiEiImUmVeE7GfgNcKe7TzezrwGPJIotIiKSTJKjMnefBEwysw7x+Szglylii4iIpJSqV+cOZvYKMCM+39bMLk8RW0REJKVUTZ2XAoOADwHcfSqwS6LYIiIiyST7Abu7z8kZ9EWq2CIiIqmk6nk5x8x2BNzM2hDO781IFFtERCSZVIXvGOCvQA9gLjABOC5RbBERaQD9KL5hUhW+Ldx9lau0mNl3gScSxRcREUki1Tm+yxo4TEREpKSKOuKLV2vZEdjAzIZnjeoEtCwmdrHMbAgwpE+fPqVMQ0REykyxTZ1tgHVjnI5ZwxcDPywydlHcfTwwvqam5ihQ27eIiARFFb6sK7aMdvf/mlnHMNiXpElPREQkrVSdWzqa2QvA+gBmtgA4zN2nJYovIiKSRKrOLSOB4e6+qbtvCpwSh4mIiJSVVIWvg7uvuBuDu08EOiSKLSIikkyqps5ZZnYWcF18/hPgrUSxRUREkkl1xPdzYAPgDuDO+PiIRLFFRESSSXU/voXo/nsiItIMJCl8ZvYI4LnD3X33FPFFRERSSXWO79Ssx+sAPwCWJ4otIiKSTKqmzik5g54ws0kpYouIiKSUqqlz/aynLYBvA19NEVtERCSlVE2dUwjn+IzQxPkWcGSi2CIiIsmkaursnSKOiIhIU0vV1HlgXePd/Y4U7yMiIlKsVE2dRxLuy/dwfL4bMBGoJTSBqvCJiEhZSFX4HNja3d8DMLONgH+4e/Krt5hZB+BR4Bx3vyd1fBERqWypLlnWK1P0og+AzRvyQjMbZWbzzGxazvDBZvaamc00s9OzRv0auLX4lEVEpBqlOuKbaGYPAjcRjv4OAR6p+yUrjAb+DozJDDCzlsA/gO8Bc4FnzWwc0B14hfAjeRERkUZL1avzBDM7ANglDhrp7nc28LWPmlmvnMH9gZnuPgvAzG4GhgLrEm53tDXwqZnd5+5f5sY0s2HAMIBNNtlkDT6RiIhUqlRHfMRC16Bi1wA9gDlZz+cCA9z9BAAzOxxYkK/oxVxGEm+EW1NTs9o1REVEpHolK3yJWZ5hKwqYu49ee6mIiEglSdW5JbW5wMZZz3sC7zYmgJkNMbORtbW1SRMTEZHmrajCZ2YPxf8XpklnhWeBzcyst5m1IXSWGdeYAO4+3t2Hde7cOXFqIiLSnBXb1LmRme0K7Bc7oKzSROnuz9cXwMxuAgYC3cxsLuH3eVeb2QnAg0BLYJS7Ty8yVxERkaIL39nA6YSmyItzxjlQ741o3f1HBYbfB9y3pomZ2RBgSJ8+fdY0hIiIVKCiCp+73wbcZmZnuft5iXJKwt3HA+NramqOKnUuIiJSPlL9ju88M9uPlb/jm6jLiYmISDlK0qvTzP4AnES4qsorwElxmIiISFlJ9Tu+fYBvZn5QbmbXAi8Av0kUv9F0jk9ERPJJ+Tu+LlmPS/4bAv2cQURE8kl1xPcH4AUze4Twk4ZdKOHRnoiISCGpOrfcZGYTge0Jhe/X7v5+itgiIiIppbxI9Xs08uoqTUnn+EREJJ9yvVZn0XSOT0RE8qnYwiciIpJP0YXPzFqY2bQUyYiIiDS1ogtf/O3eVDPTrc5FRKTspercshEw3cwmA0szA919v0TxRUREkkhV+M5NFCcZ9eoUEZF8knRucfdJwGygdXz8LFDvvfiaknp1iohIPqkuUn0UcBtwZRzUA7grRWwREZGUUv2c4Xjgu8BiAHd/A9gwUWwREZFkUhW+z939f5knZtaKcAd2ERGRspKq8E0yszOAdmb2PWAsMD5RbBERkWRSFb7TgfnAy8DRwH3AbxPFXiNmNsTMRtbW1pYyDRERKTOp7s7wZbz57DOEJs7X3L2kTZ3uPh4YX1NTc1Qp8xARkfKSpPCZ2T7AFcCbhNsS9Tazo939/hTxRUREUkn1A/a/ALu5+0wAM/s6cC+gwiciImUl1Tm+eZmiF80C5iWKLSIikkxRR3xmdmB8ON3M7gNuJZzjO4hw9RYREZGyUmxT55Csxx8Au8bH84H1iowtIiKSXFGFz92PSJWIiIjI2pCqV2dv4ESgV3bMUt6WSHdnEBGRfFL16rwLuJpwtZYvE8Usin7HJyIi+aQqfJ+5+98SxRIREWkyqQrfX83sHGAC8HlmoLuX9J58IiIiuVIVvn7AT4HdWdnU6fG5iIhI2UhV+A4AvpZ9ayIREZFylOrKLVOBLoliiYiINJlUR3xfAV41s2dZ9RxfyX7OICIikk+qwndOojgiIiJNKtX9+CaliCMiItLUUl255WNCL06ANkBrYKm7d0oRX0REJJVUR3wds5+b2f5A/xSxRUREUkrVq3MV7n4XJf4Nn5kNMbORtbW1pUxDRETKTKqmzgOznrYAaljZ9FkSulaniIjkk6pXZ/Z9+ZYDs4GhiWKLiIgkk+ocn+7LJyIizUJRhc/Mzq5jtLv7ecXEFxERSa3YI76leYZ1AI4EugIqfCIiUlaKKnzu/pfMYzPrCJwEHAHcDPyl0OtERERKpehzfGa2PjAcOBS4FtjO3RcWG1dERKQpFHuO78/AgcBIoJ+7L0mSlYiISBMp9gfspwDdgd8C75rZ4vj3sZktLj49ERGRtIo9x9ckV34RERFpKipcIiJSVVT4RESkqqjwiYhIVVHhExGRqqLCJyIiVaVZFT4z28rMrjCz28zs2FLnIyIizU/JC5+ZjTKzeWY2LWf4YDN7zcxmmtnpAO4+w92PAf4f4Z5/IiIijVLywgeMBgZnDzCzlsA/gL2ArYEfmdnWcdx+wOPAQ2s3TRERqQQlL3zu/ijwUc7g/sBMd5/l7v8jXPR6aJx+nLvvSLg2aF5mNszMnjOz5+bPn99UqYuISDOU6g7sqfUA5mQ9nwsMMLOBhGuDtgXuK/Ridx9JuH4oNTU13mRZiohIs1Ouhc/yDHN3nwhMXLupiIhIJSl5U2cBc4GNs573BN5tTAAzG2JmI2tra5MmJiIizVu5Fr5ngc3MrLeZtQEOAcY1JoC7j3f3YZ07d26SBEVEpHkqeeEzs5uAp4AtzGyumR3p7suBE4AHgRnAre4+vZR5iohIZSj5OT53/1GB4fdRRwcWERGRNVHyI76monN8IiKST8UWPp3jExGRfCq28ImIiORTsYVPTZ0iIpJPxRY+NXWKiEg+FVv4RERE8lHhExGRqqLCJyIiVaXkP2BvKmY2BBjSp0+fUqciJfSDRWOLev19fCdRJiJSLiq28Ln7eGB8TU3NUaXORUTWnokfFP9ld68EeUj5qtjC11xNe+2ComNsP3B8gkxERCqTzvGJiEhVUeETEZGqUrFNnercIlL+/rZw06Jj/DpBHlJdKrbwqXNL0xoz55yiXn80DybKRESkcSq28MlKE2adW3SMoQPvT5CJiEjpqfCJSIP89MM2Rce4LUEeIsVS5xYREakqKnwiIlJVKrapc2306lz0yp1Fx2g3UJfEEil3s17tXXSMvgOLz0PSqNjCp16d0hR++NGzRce4V9f/FCmpii18Is3FQQveLDrGPSqmIg2mwidlY8SCEUW9/kIeSJOIiFQ0dW4REZGqosInIiJVRYVPRESqis7xiVSgQxYsLDrG3QnyEClHVVP4lsyYWXQM/eZORKT5q9imTjMbYmYja2trS52KiIiUkYotfO4+3t2Hde7cudSpiIhIGanYwiciIpKPCp+IiFQVFT4REakqVdOrU0SknNRO6VJ0jHYDiw5RlXTEJyIiVUWFT0REqooKn4iIVBWd4xMRqRAfv/xp0TGq4byhjvhERKSqVGzh0yXLREQkn4otfLpkmYiI5FOxhU9ERCQfFT4REakqKnwiIlJVVPhERKSqqPCJiEhVUeETEZGqYu5e6hyalJnNB/7bgEm7AQsSv71iKqZill/M5pBjOcTc1N03SPz+ZaHiC19Dmdlz7l6jmIqpmJUdsznk2JxiNkdq6hQRkaqiwiciIlVFhW+lkYqpmIpZFTGbQ47NKWazo3N8IiJSVXTEJyIiVUWFT0REqkrVFz4zG2Vm88xsWsKYG5vZI2Y2w8ymm9lJCWKuY2aTzWxqjHluolxbmtkLZnZPingx5mwze9nMXjSz5xLF7GJmt5nZq3G+7lBkvC1ifpm/xWZ2cpExfxWXzTQzu8nM1ikmXox5Uow3fU3zy7eOm9n6ZvZvM3sj/l8vQcyDYp5fmlmju8wXiPnnuMxfMrM7zaxLgpjnxXgvmtkEM+tebMyscaeamZtZtwR5jjCzd7LW0b1T5GlmJ5rZa3FZ/akxMSuGu1f1H7ALsB0wLWHMjYDt4uOOwOvA1kXGNGDd+Lg18AzwnQS5DgduBO5J+PlnA90SL6drgV/Ex22ALgljtwTeJ/xgd01j9ADeAtrF57cChxeZ1zeAaUB7oBXwH2CzNYiz2joO/Ak4PT4+HbgwQcytgC2AiUBNojy/D7SKjy9MlGenrMe/BK4oNmYcvjHwIOGCGY1a/wvkOQI4tYj1J1/M3eJ61DY+37CYdbS5/lX9EZ+7Pwp8lDjme+7+fHz8MTCDsGMsJqa7+5L4tHX8K6pnkpn1BPYB/lVMnKZmZp0IG/HVAO7+P3dflPAt9gDedPeGXOGnLq2AdmbWilCs3i0y3lbA0+7+ibsvByYBBzQ2SIF1fCjhywTx//7FxnT3Ge7+WmPzqyfmhPjZAZ4GeiaIuTjraQcauR3Vsc+4BDitsfHqibnGCsQ8Fviju38ep5mX8j2bi6ovfE3NzHoB3yIcoRUbq6WZvQjMA/7t7sXGvJSwoX5ZZJxcDkwwsylmNixBvK8B84FrYrPsv8ysQ4K4GYcANxUTwN3fAS4C3gbeA2rdfUKReU0DdjGzrmbWHtibcFSRwlfc/T0IX9SADRPFbUo/B+5PEcjMLjCzOcChwNkJ4u0HvOPuU4tOblUnxGbZUY1tji5gc2BnM3vGzCaZ2fYJYjY7KnxNyMzWBW4HTs75lrlG3P0Ld/8m4VtvfzP7RhG57QvMc/cpxeaVx3fdfTtgL+B4M9ulyHitCE02/3T3bwFLCc1zRTOzNsB+wNgi46xHOIrqDXQHOpjZT4qJ6e4zCM17/wYeAKYCy+t8UYUyszMJn/2GFPHc/Ux33zjGO6HI3NoDZ5KggOb4J/B14JuEL1N/SRCzFbAe8B3g/4BbzcwSxG1WVPiaiJm1JhS9G9z9jpSxYzPfRGBwEWG+C+xnZrOBm4Hdzez6opMD3P3d+H8ecCfQv8iQc4G5WUe4txEKYQp7Ac+7+wdFxtkTeMvd57v7MuAOYMdik3P3q919O3ffhdBs9UaxMaMPzGwjgPi/bJu8zOwwYF/gUI8nphK6EfhBkTG+TvjCMzVuTz2B583sq8UEdfcP4pfdL4GrKH47grAt3RFPnUwmtPY0qiNOJVDhawLxG9TVwAx3vzhRzA0yPdrMrB1hR/vqmsZz99+4e09370Vo6nvY3Ys6Qom5dTCzjpnHhM4JRfWYdff3gTlmtkUctAfwSlGJrvQjimzmjN4GvmNm7ePy34NwbrcoZrZh/L8JcCBpcgUYBxwWHx8G3J0oblJmNhj4NbCfu3+SKOZmWU/3o4jtCMDdX3b3Dd29V9ye5hI6t71fTNzMF5PoAIrcjqK7gN1j/M0JHcVS3wGi/JW6d02p/wg7kveAZYQV9sgEMXcinOd6CXgx/u1dZMxtgBdizGnA2QnnwUAS9eoknI+bGv+mA2cmivtN4Ln4+e8C1ksQsz3wIdA5UY7nEnai04DriD3nioz5GKHITwX2WMMYq63jQFfgIcIR5EPA+gliHhAffw58ADyYIOZMYE7WdtTYHpj5Yt4el9FLwHigR7Exc8bPpvG9OvPleR3wcsxzHLBRgphtgOvj538e2D3Fut/c/nTJMhERqSpq6hQRkaqiwiciIlVFhU9ERKqKCp+IiFQVFT4REakqKnwiCZjZJdl3TzCzB83sX1nP/2JmwxsZc7SZ/TBhmiKCCp9IKk8Sr9RiZi0IV8PomzV+R+CJEuQlIjlU+ETSeIKVlyjrS/iB8Mdmtp6ZtSXcaYF4YeAp8Ygwc8mwr5vZA3H4Y2a2ZW7weA+50bGoikgRWpU6AZFK4O7vmtnyeGmxHYGnCLei2gGoJVy+7BJgqLvPN7ODgQsIdxwYCRzj7m+Y2QDgcuJlpQDizUI7A0e4rjghUjQVPpF0Mkd9OwIXEwrfjoTC9w7huqX/jhfDbwm8F+/gsSMwNusi+W2zYp4FPOPuKW7vJCKo8ImklDnP14/Q1DkHOAVYDDxMuCbkDtkviDfZXeThdlP5PAt828zWd/ekNyoVqVY6XyCSzhOE2+d85OF2Mh8BXQjNnbcAG5jZDhBuW2VmfT3cp/EtMzsoDjcz2zYr5gPAH4F7M3e9EJHiqPCJpPMyoTfn0znDaj3cm/CHwIVmNpVwp4FMZ5hDgSPj8OmEG9qu4O5jCfdjGxdvSSUiRdDdGUREpKroiE9ERKqKCp+IiFQVFT4REakqKnwiIlJVVPhERKSqqPCJiEhVUeETEZGq8v8Bh7Z+kHsuyIoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=df_count.index[:16],y=df_count.iloc[:16]['male'], color='lightblue', label='male')\n",
    "sns.barplot(x=df_count.index[:16],y=df_count.iloc[:16]['female'], color='lightpink', label='female')\n",
    "sns.barplot(x=df_count.index[:16],y=df_count.iloc[:16]['others'], label='others')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Number of quotes')\n",
    "plt.title('Comparing the distribution of quote speakers among genders per week')\n",
    "plt.legend()\n",
    "plt.rcParams['figure.figsize'] = (10,7)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this logarithmic-scale plot, we can clearly see the difference in the importance of each gender in media. The distribution of men and women speakers through time is roughly the same (see correlation below). However, for LGBT+ (other) speakers, they are rarer and seem to speak in peaks which might be correlated with events that happened that week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation : (Pearson correlation coefficient, p-value)\n",
      "Male/Female : (0.9863442003930507, 2.2905848236518718e-12)\n",
      "LGBT+/Total : (0.6518193884509832, 0.006220202646455371)\n"
     ]
    }
   ],
   "source": [
    "print('Correlation : (Pearson correlation coefficient, p-value)')\n",
    "print(f'Male/Female : {stats.pearsonr(df_count.iloc[:16][\"male\"], df_count.iloc[:16][\"female\"])}')\n",
    "print(f'LGBT+/Total : {stats.pearsonr(df_count.iloc[:16][\"others\"], df_count.iloc[:16][\"all\"])}') # Lower correlation due to rarer data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Irregularities in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Speaker not repertiored:\n",
    "get speaker QID from \\[speaker_noMeta\\] and input it in \\[df_parquet\\] as follow:\n",
    "``` python\n",
    "i = 0\n",
    "df_parquet[df_parquet.id == speaker_noMeta.iloc[i].values[0]]\n",
    "```\n",
    "> should return an empty DataFrame\n",
    "\n",
    "Example:\n",
    "\n",
    "i = 0 : [Q59209387](https://www.wikidata.org/wiki/Q59209387) does not exist\\\n",
    "i = 1 : [Q30337200](https://www.wikidata.org/wiki/Q30337200) Philippe Bouyer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Gender not described:\n",
    "*See first two rows of output of this [cell](#error1)*\n",
    "If the link does not work, it is the output of python cell number 13."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Gender is not a real gender\n",
    "*See explanation in this [cell](#error2)*\n",
    "If the link does not work, it is the explanation under python cell number 13."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Creating datasets D3 and D2 and storing them for later use (see README)***\n",
    "\n",
    "In the README, we have mentioned in the **Methods** paragraph that there will be subsets to D2 and D3. In this notebook, we will only create D3. \n",
    "This is because D2 is in fact a subset of D3 (see `helper.py` for the definition of our keywords). The rest of the datasets will be derived from D3 for milestone 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import json\n",
    "import pickle as pkl\n",
    "from time import time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from helper import keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started filtering year 2020:\n",
      "   -Time elapsed to filter year 2020: 407.016 seconds\n",
      "   -Time elapsed to write pickle for year 2020: 47.009 seconds\n"
     ]
    }
   ],
   "source": [
    "# Uncomment in order to run for all years, here we just give the TA's 2020 for time purposes\n",
    "years = reversed(range(2020, 2021))\n",
    "# years = reversed(range(2015, 2021))\n",
    "\n",
    "for year in years:\n",
    "    print(f'Started filtering year {year}:')\n",
    "\n",
    "    path_to_file = f'data/quotes-{year}.json.bz2'\n",
    "    path_to_out = f'data/filtered/quotes-{year}-filtered.json.bz2'\n",
    "    path_to_pkl = f'data/filtered/pickles/quotes-{year}-filtered.pkl.bz2'\n",
    "\n",
    "    begin = time()\n",
    "    with bz2.open(path_to_file, 'rb') as s_file:\n",
    "        with bz2.open(path_to_out, 'wb') as d_file:\n",
    "            for instance in s_file:\n",
    "                instance = json.loads(instance)  # loading a sample\n",
    "\n",
    "                quote = str(instance['quotation']).lower()\n",
    "\n",
    "                for word in keywords:\n",
    "                    if word in f' {quote} ':\n",
    "                        # writing in the new file\n",
    "                        d_file.write(\n",
    "                            (json.dumps(instance)+'\\n').encode('utf-8'))\n",
    "                        break\n",
    "    end = time()\n",
    "    print(f'   -Time elapsed to filter year {year}: {end-begin:.3f} seconds')\n",
    "\n",
    "    begin = time()\n",
    "    with bz2.open(path_to_pkl, 'wb') as f:\n",
    "        data_reader = pd.read_json(\n",
    "            path_to_out, lines=True, compression='bz2', chunksize=CHUNK_SIZE)\n",
    "        for chunk in data_reader:\n",
    "            pkl.dump(chunk, f)\n",
    "    end = time()\n",
    "    print(\n",
    "        f'   -Time elapsed to write pickle for year {year}: {end-begin:.3f} seconds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** As already mentioned, this is only the output for the year 2020.\n",
    "\n",
    "We have run the parsing code for every year in `[2015;2020]` and we got the following results:\n",
    "\n",
    "Year | Original Size | Filtered Size | Pickle Size | Time to filter |\n",
    ":---:|:-------------:|:-------------:|:-----------:|:--------------:|\n",
    "2020 |792.3 MB       |59.7 MB        |55 MB        |6 min 47s       |\n",
    "2019 |3.32 GB        |345.4 MB       |318.2 MB     |39 min 5s       |\n",
    "2018 |4.48 GB        |462.6 MB       |425.8 MB     |52 min 14s      |\n",
    "2017 |4.84 GB        |447.6 MB       |411.2 MB     |50 min 30s      |\n",
    "2016 |2.16 GB        |210.1 MB       |193.1 MB     |23 min 42s      |\n",
    "2015 |3.11 GB        |293 MB         |269.2 MB     |33 min 1s       |\n",
    "Total|18.7 GB        |1.82 GB        |1.67 GB      |3h 25 min 19s   |\n",
    "\n",
    "*N.B: file sizes correspond to the .bz2 compressed files and they depend on the compression algorithm in each OS*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that dataset D3 is approximately 10 times smaller than the whole Quotebank, which focuses more towards answering our questions. We can also expect to miss a lot of quotes mentioning women, as well as take in D3 quote that do not mention women seeing that we are just taking the quotes mentioning them explicitely through our defined dictionary. But this is still enough for us to conduct our observations.\n",
    "\n",
    "The creation of the pickle files is a way to load the data faster for later uses. The size of the data makes its handling take time in the order of hours which would be much more decreased when loading from pickle files, which reduces waiting time by a factor of ~9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What follow is a more detailed explanation of the __Methods__ paragraph in the __README__*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Step 1: Data scraping, pre-processing and dataset construction.**\\\n",
    "  This is what has been run in the notebook\n",
    "\n",
    "* **Step 2: General preliminary analysis using Quotebank entire dataset.**\\\n",
    "  In this step, we will plot the weekly percentage of quotes by author’s gender (men, women, other, unknown) from 2015 to 2020. This will allow us to have a general perspective on the place that women are being given in the mediatic place through time.\n",
    "  With our result, we will see if the place given to woman, in terms of weekly percentage of speaker, correlates with the #MeToo movement important dates.\n",
    "\n",
    "* **Step 3: Generate annual word clouds based on dataset D1.**\n",
    "  From this, it would be interesting to use dataset D1 (containing all the quotes from women authors) to make a deeper analysis on the women’s quotes. By creating annual or 6-monthly word clouds, we would like to identify the main topics discussed by women in these quotes through time. ([Library possibly used](https://github.com/amueller/word_cloud))\n",
    "\n",
    "* **Step 4: Investigate gender, political and generational biases in MeToo coverage using NLP to answer question A) with dataset D2.**\\\n",
    "  In this part, we will try to answer question A). For this, we will use dataset D2 and its subsets D2.1, D2.2 and D2.3, and we will train an NLP model (e.g. [spacy](https://spacy.io/usage/training)) with dataset AD3 to perform sentiment analysis on them. We will then perform a classification thanks to the trained NLP model on the whole dataset D2. By then subdividing D2 into D2.1, D2.2 and D2.3, we will perform the following analysis:\n",
    "  1. **Investigate the gender biases:**\\\n",
    "    Plotting the percentages of men and women’s quotes in D2 and comparing them with the result obtained in step 1. We will see therefore if the way women are given voices differs talking about MeToo or in general.\n",
    "    Thanks to the sentiment analysis previously performed, we will be able to identify any difference in tone between the gender by plotting distributions and visualizing the classes for quotes of each gender.\n",
    "    We will generate word clouds for quotes of each gender to get a sense of the words most used when talking about MeToo depending on the gender.\n",
    "\n",
    "  2. **Investigate political biases:**\\\n",
    "    Plotting the percentage of quotes in D2 for the different political parties.\n",
    "    Thanks to the sentiment analysis previously performed, we will be able to identify any difference in tone between the political parties by plotting distributions and visualizing the classes for quotes of each party.\n",
    "    We will generate word clouds for quotes of each political party to get a sense of the words most used when talking about MeToo depending on the gender.\n",
    "\n",
    "  3. **Investigate generational biases:**\\\n",
    "    Plotting the percentage of quotes in D2 for the different age groups\n",
    "    Thanks to the sentiment analysis previously performed, we will be able to identify any difference in tone between the age groups by plotting distributions and visualizing the classes for quotes of each group.\n",
    "    We will generate word clouds for quotes of each age group to get a sense of the words most used when talking about MeToo depending on the age and gender.\n",
    "\n",
    "  4. **Inherent biases in the structure of dataset D2:**\\\n",
    "    Various clustering trials with unsupervised different ML algorithms applied on the sentiment analysis classification probabilities returned previously. This aims at revealing clusters and therefore biases inherent to the data.\n",
    "\n",
    "* **Step 5: Investigate general women perception via quotes mentioning women (dataset D3) in media to answer question B).**\\\n",
    "  This step aims to answer the question of the general perception of women in the media. We will investigate this problematic by using two different classifying NLP models applied to D3.\n",
    "  Generate 6-monthly word clouds.\n",
    "  Text Blob or Vader models for classifying the quotes as positive, negative or neutral. These NLP models return probabilities for the tone to be positive or negative. Probabilities thresholds will have to be set to determine the class boundaries.\n",
    "  We will then train the SpaCy model on AD2 for classifying the quotes as misogynistic or non misogynistic. The trained model will then be used to classify the quotes of D3. Finally, we will plot the distributions of quote classes with respect to time.\n",
    "\n",
    "* **Step 6: Correlate and investigate causation between MeToo general perception and women’s mediatic place to answer question C).**\\\n",
    "  This last step aims at answering if the evolution of women’s mediatization is correlated and has been tuned by the tendencies of MeToo’s mediatic perspective. To that end, we will make timelines, plot the data distributions and information previously collected, according to time, and compare them to major turning points and mediatization phases of the MeToo movement. We will investigate the statistical significance of the detected changes, variations of women’s mediatic place and mediatization before and after MeToo, thanks to adapted statistical tests.\n",
    "\n",
    "* **Step 7: Github site building and Datastory redaction.**\\\n",
    "  MeToo movement timeline that will be useful for the Datastory and Data Analysis:\n",
    "  In order to correlate our analysis with the key turning points and dates of the MeToo movement, we will use week bins, week timespans.\n",
    "  This non-exhaustive list can be further completed thanks to the dates and key turning points of the MeToo movement, thanks to the data available on [this webpage.](https://www.refinery29.com/en-us/2018/10/212801/me-too-movement-history-timeline-year-weinstein)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4852a97ec4b58736f61deb13d50476656e96c2a7bbb0af5e2c3f5eb588ff8009"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('ada': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
